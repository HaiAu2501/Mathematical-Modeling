{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn # Neural network module\n",
    "import torch.optim as optim # Optimization module\n",
    "import torch.nn.functional as F # Functional module\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Pointer Network**, also known as Ptr-Net, is a neural network architecture introduced by Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly in their 2015 paper \"Pointer Networks\". Pointer Networks are a type of neural network that can learn to generate sequences by pointing to positions in the input sequence. Conventional sequence-to-sequence models like RNNs, LSTMs, and Transformers generate sequences by predicting the next token in the output sequence at each time step. In contrast, Pointer Networks generate sequences by selecting positions in the input sequence as output.\n",
    "\n",
    "Pointer Networks use attention mechanisms to directly select positions in the input sequence as output. This capability is particularly useful for problems like the Traveling Salesman Problem (TSP), the Delaunay Triangulation, and various other combinatorial problems where the solution is a sequence derived from a given set of inputs. \n",
    "\n",
    "In this notebook, we will implement a Pointer Network to solve the sorting problem. Given a sequence of numbers, the Pointer Network will learn to sort the numbers in ascending order by selecting positions in the input sequence as output. We will use the PyTorch library to implement the Pointer Network and train it on a synthetic dataset of unsorted sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence Models\n",
    "\n",
    "> To write this section, I referred to the following resources:\n",
    "> - Sutskever, Ilya, Oriol Vinyals, and Quoc V. Le. *Sequence to sequence learning with neural networks.* Advances in neural information processing systems 27 (2014).\n",
    "> - Cho, Kyunghyun, et al. *Learning phrase representations using RNN encoder-decoder for statistical machine translation.* arXiv preprint arXiv:1406.1078 (2014).\n",
    "> ---\n",
    "\n",
    "**Sequence-to-sequence models** (Seq2Seq) are a class of neural networks that take a sequence as input and produce a sequence as output. They are widely used in machine translation, text summarization, speech recognition, and other sequence generation tasks. \n",
    "\n",
    "The basic architecture of a sequence-to-sequence model consists of an **encoder** and a **decoder**. The encoder processes the input sequence and encodes it into a fixed-size representation, while the decoder generates the output sequence based on the encoded representation. Specifically,\n",
    "\n",
    "1. The encoder processes the input sequence and compresses the information into a fixed-size **context vector**. This context vector encapsulates the entire information of the input sequence. The encoder can be an RNN, LSTM, or GRU network that processes the input sequence one element at a time and produces a sequence of hidden states.\n",
    "\n",
    "2. The decoder generates the output sequence from the context vector provided by the encoder. Similar to the encoder, the decoder can also be an RNN, LSTM, or GRU network. It produces one element of the output sequence at a time and can use the previously generated elements as additional input.\n",
    "\n",
    "We talk about the mathematical formulation of the sequence-to-sequence model. At this point, we use Recurrent Neural Networks (RNNs) as the building blocks of the encoder and decoder. However, it is important to note that other architectures like Long Short-Term Memory (LSTMs) networks and Gated Recurrent Units (GRUs) can also be used in place of RNNs.\n",
    "\n",
    "Given an input sequence $\\mathbf{X} = (\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_T)$ and an output sequence $\\mathbf{Y} = (\\mathbf{y}_1, \\mathbf{y}_2, \\ldots, \\mathbf{y}_{T})$ where $\\mathbf{x}_t, \\mathbf{y}_t \\in \\mathbb{R}^{d \\times 1}$, the encoder processes the input sequence to obtain a sequence of hidden states $\\mathbf{H} = (\\mathbf{h}_1, \\mathbf{h}_2, \\ldots, \\mathbf{h}_T)$. The hidden state $\\mathbf{h}_t \\in \\mathbb{R}^{p\\times 1}$ at time step $t$ is computed as a function of the input $\\mathbf{x}_t$ and the previous hidden state $\\mathbf{h}_{t-1}$, i.e., $\\mathbf{h}_t = f(\\mathbf{x}_t, \\mathbf{h}_{t-1})$. We can choose the function $f$ to be a simple linear transformation followed by an activation function, such as the $\\text{sigmoid}$ or $\\text{tanh}$ function.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_t = \\text{sigmoid}\\left(\\mathbf{W}^{\\text{hx}} \\mathbf{x}_t + \\mathbf{W}^{\\text{hh}} \\mathbf{h}_{t-1}\\right) \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}^{\\text{hx}} \\in \\mathbb{R}^{p\\times d}$ and $\\mathbf{W}^{\\text{hh}} \\in \\mathbb{R}^{p\\times p}$ are the weight matrices, and $\\text{sigmoid}$ is the activation function. The initial hidden state $\\mathbf{h}_0$ is usually set to zero. The context vector is computed as the last hidden state $\\mathbf{h}_T$.\n",
    "\n",
    "We can rewrite the above equation in matrix form as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_t = \\text{sigmoid}\\left( \\underbrace{\\begin{bmatrix} \\mathbf{W}^{\\text{hx}} & \\mathbf{W}^{\\text{hh}} \\end{bmatrix}}_{\\mathbf{W}} \\begin{bmatrix} \\mathbf{x}_t \\\\ \\mathbf{h}_{t-1}\\end{bmatrix} \\right) \\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W} \\in \\mathbb{R}^{p\\times (d+p)}$ is the weight matrix. The concatenation of $\\mathbf{x}_t$ and $\\mathbf{h}_{t-1}$ which is a collumn vector of size $(d+p)$ is fed to the weight matrix $\\mathbf{W}$ to compute the hidden state $\\mathbf{h}_t$.\n",
    "\n",
    "The output is computed by following equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{y}_t = \\mathbf{W}^{\\text{hy}} \\mathbf{h}_t \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}^{\\text{hy}} \\in \\mathbb{R}^{d\\times p}$ is the weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a simple RNN\n",
    "class RNN(nn.Module):\n",
    "\tdef __init__(self, input_size, hidden_size, output_size):\n",
    "\t\tsuper(RNN, self).__init__()\n",
    "\t\tself.hidden_size = hidden_size\n",
    "\t\tself.input_size = input_size\n",
    "\t\tself.output_size = output_size\n",
    "\n",
    "\t\t# Define linear layers\n",
    "\t\tself.i2h = nn.Linear(input_size + hidden_size, hidden_size) # W^ih * [x_t, h_t-1]\n",
    "\t\tself.h2o = nn.Linear(hidden_size, output_size) # W^ho * h_t\n",
    "\n",
    "\t\t# Define activation function\n",
    "\t\tself.activation = nn.Sigmoid()\n",
    "\n",
    "\tdef forward(self, input, hidden):\n",
    "\t\tcombined = torch.cat((input, hidden), 1) # [x_t, h_t-1], torch.cat concatenates along the second dimension\n",
    "\t\thidden = self.activation(self.i2h(combined)) # h_t = sigmoid(W^ih * [x_t, h_t-1])\n",
    "\t\toutput = self.h2o(hidden) # y_t = W^ho * h_t\n",
    "\t\treturn output, hidden # Need to return hidden state for next time step\n",
    "\t\n",
    "\tdef init_hidden(self):\n",
    "\t\treturn torch.zeros(1, self.hidden_size) # Initialize hidden state to zeros, which is the same as h_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 48.11879348754883\n",
      "Epoch 100 Loss: 0.04491451010107994\n",
      "Epoch 200 Loss: 0.002114828210324049\n",
      "Epoch 300 Loss: 0.0006631762371398509\n",
      "Epoch 400 Loss: 0.0002964616578537971\n",
      "Epoch 500 Loss: 0.00016455202421639115\n",
      "Epoch 600 Loss: 0.00011110841296613216\n",
      "Epoch 700 Loss: 8.592118683736771e-05\n",
      "Epoch 800 Loss: 0.010202344506978989\n",
      "Epoch 900 Loss: 7.951374573167413e-05\n",
      "Test loss: 0.024877655746716455\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAGdCAYAAAAfTAk2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAACd5ElEQVR4nOzdeXycZdX4/889M5nJOtmTyb51h9JCgVpAFi20gAqKCIoiiPAVrYqgSJ+fgIKKK4+APODDIvAIghuIoAWsls3SQktXuiTNvkz2ZJJJMuv9++OemSRt2iZtZu5Zzvv1mhdhcs/MSZsmZ67rnOsoqqqqCCGEEELEEYPeAQghhBBCzDZJcIQQQggRdyTBEUIIIUTckQRHCCGEEHFHEhwhhBBCxB1JcIQQQggRdyTBEUIIIUTckQRHCCGEEHHHpHcAevD7/bS3t5ORkYGiKHqHI4QQQohpUFWVoaEhiouLMRiOvEaTkAlOe3s7ZWVleochhBBCiGPQ0tJCaWnpEa9JyAQnIyMD0P6ArFarztEIIYQQYjocDgdlZWWh3+NHkpAJTnBbymq1SoIjhBBCxJjplJdIkbEQQggh4o4kOEIIIYSIO5LgCCGEECLuSIIjhBBCiLgjCY4QQggh4o4kOEIIIYSIO5LgCCGEECLuhDXBeeONN/j4xz9OcXExiqLwwgsvHPUxGzZs4JRTTsFisTBnzhyeeOKJQ6558MEHqaysJDk5meXLl7N58+bZD14IIYQQMSusCY7T6WTJkiU8+OCD07q+oaGBiy++mPPOO49t27Zx00038eUvf5lXXnkldM1zzz3HzTffzJ133snWrVtZsmQJq1atoqurK1xfhhBCCCFijKKqqhqRF1IUnn/+eS699NLDXvPd736Xl19+mV27doXuu/LKKxkYGGDdunUALF++nNNOO41f//rXgDY4s6ysjK9//evcdttt04rF4XCQmZnJ4OCgnGQshBBCxIiZ/P6OqhqcjRs3snLlykn3rVq1io0bNwLgdrvZsmXLpGsMBgMrV64MXTMVl8uFw+GYdBNCCCFE/IqqBMdut1NYWDjpvsLCQhwOB6Ojo/T09ODz+aa8xm63H/Z577nnHjIzM0M3mSQuhBBCxLeoSnDCZe3atQwODoZuLS0teockhBAijMY8Ph55/QAtfSN6hyJ0ElUJjs1mo7Ozc9J9nZ2dWK1WUlJSyMvLw2g0TnmNzWY77PNaLJbQ5HCZIC6EEPHvT39+jiv/dSZvP/1DvUMROomqBGfFihWsX79+0n2vvfYaK1asAMBsNrNs2bJJ1/j9ftavXx+6RgghRGIbHHFz4p7/JkMZZWnvy/j9EemlEVEmrAnO8PAw27ZtY9u2bYDWBr5t2zaam5sBbevo6quvDl3/la98hfr6em699Vb27t3L//zP//CHP/yBb33rW6Frbr75Zh555BGefPJJ9uzZw4033ojT6eTaa68N55eSEL79x+184tdvMTDi1jsUIYQ4Zutf+StLlf0AzFWbaGxr1zkioQdTOJ/8vffe47zzzgv9/8033wzAF7/4RZ544gk6OjpCyQ5AVVUVL7/8Mt/61re47777KC0t5dFHH2XVqlWha6644gq6u7u54447sNvtLF26lHXr1h1SeCxmZnDUw5+2tALwy1f3c/elJ+ockRBCzNyYx0f+jodC/29UVJp3vEF12Wd1jEroIWLn4EQTOQfnUG/WdvOFx7QToQ0KvLjmLE4sydQ5KiGEmJmX//kaF7/1afwotKUvpmx4B6/mfZEL1tyvd2hiFsTsOThCP9tbBkIf+1W488Xdsm8thIgpPr9K0sYHAGgqWMnIwssByOvbqmdYQieS4AgAtgUSnBvOribVbGRLUz/Pv9+mb1BCCDEDGza9x0e8bwJgu/g2SpZ8BICFvn10DwzrGZrQgSQ4AlVVQwnOqhNsfOOjcwG45x97cYx5dIxMCCGmR1VVnK/fh0nx05R5OikVp5JevAiHkkGK4qZ2x3/0DlFEmCQ4gtb+UXqG3SQZFU4otvKlM6uozkujZ9jFr16r1Ts8IYQ4qk279nH+qDaYOXvVd7U7DQbaMxYDMLz/Tb1CEzqRBEewvXUAgIVFVpKTjJhNBr7/iRMAeHJjI/vsQzpGJ4QQR9f+6n2kKG7aUxdgXfjR0P2+0g8BkNH1nl6hCZ1IgiPY1jwAwJLSrNB9Z8/LZ/UJNnx+lTv+uosEbLYTQsSIXQ1tfMTxVwAs594CihL6XN6icwCY49rNqMurS3xCH5LgiFD9zdKyrEn3f+9jC0lOMrCpoY+/7eiIfGBCCDENe19+gCzFSZe5lNxTL5v0uYL5y3FjIl8ZZO+e7TpFKPQgCU6C8/j87GwbBGBpedakz5Vmp/K1c+cA8KOXP2BY3v2IcPK6wdkDvQegbQsc+DfsfgG2PgV7X9Y7OhGlGjr7OaP7OQD8H/o6GIyTPq8kpdCSvACA3j1vRDw+oZ+wnmQsot8++xAurx9rsomq3LRDPn/92dX8aWsrTb0jPPCvWtZeuFCHKEXUU1VwO2FsEFwO7b9jgzDmgLGBKe6b4jrv6JFf40uvQPmHIvLliNjx3t9+w+VKHwPGXGxnTz2yx2k7DRp3kdS2KcLRCT1JgpPggttTS8qyMBiUQz6fnGTkzo8v4ktPvMdjbzZw+bIy5hSkRzhKEdX2vwp/uhbcs3TOiDkDkjMh2YrfYsXb04B5tBPatkqCIybpGhzh5JanQIGhpV8my2SZ8rrMeWdB428pG96B369O+bNOxB9JcBLc4epvJvrIgkI+uqCA9Xu7+P6Lu/m/605HUeQHhAjY9efx5MZgCiQnmWCxhhIV7f8zxz8Xum/yNSNKKltbhtjc0Ms7DX1saxjga/yBb5r+Qm/DNnJX6Puliujy5kv/x2VKG04ljbLz1xz2upLF58KrUE0btU1NzK2qjFiMQj+S4CS46SQ4AHd8fBFv1vXwVl0P63bZuXBxUfiDE7GhZ5/2308/Did8alIHy9EMjnh4r6mPzQ19bGpoY1fbIN6DRoTsN5YC4LN/MGshi9jnGHUzZ/8joEDX/KuoSj78XCJTRh6tpgpKvU207dzA3KprIhan0I8kOAnMMebhQLf2znvJURKcitw0vnJ2Nff/q467X/qAc+cXkGI2HvExIgGoKvQEDoMsPPGoyU33kIt3G4MJTR977Q4OPoGgJCuF5VU5nB64vfEfE7x/P9bhOvD7wSC9EQL+9coLXKrU4iaJiotuOer1/bknU9rZhL9xI3BN2OMT+pMEJ4HtbB1EVaE0O4W89Kn3rie68dw5/HlrG20Dozz47zq+vWp+BKIUUc3Rpm1PGUyQU33Ip9sGRtnc0BtKaOq7nYdcU52fFkpoTqvMoTQ7ddLn91cuxLXVRLJ/FAZbILsibF+OiA1jHh/52/8HgJaKT1JjtR31MebqM6HzBfIGtoU5OhEtJMFJYNPdngpKMRu5/WOL+MrvtvC/b9Tz6WWlVOYd2nklEkh3YHsqpxrVYKKhe5jNDeMrNG0DkzujFAUW2KyTEpr8jCMn1/OKc6hXi1moNOPr/ACjJDgJ718b/sVF6vv4MFB28Xen9ZjSJefBRljgq6Wzt5/C3OwwRyn0JglOAptpggOw6oRCPjw3jzdre/jB33bz+DWnScFxIuvZD8D2sUKu+9F6eoZdkz5tNCgsLskMJTSnVuSQmZo0o5eoyE3j75SxkGYGGreTu+DCWQtfxB6fXyXpnfsBaCo8n+qCOdN6XFrhHPqUbHLo58D2tyj8yMfDGaaIApLgJKiJE8RnkuAoisL3P3ECq3/1Bv/e1836PV2sXFQYniBF9Aus4Lw5kEOP14XZZODksqxAQpPLyeVZpFmO78eM0aDQnz4HRt5mrG3XbEQtYtjrm97jPO9boEDRRbdN/4GKQkfmUnIG/s1I3VsgCU7ckwQnQbUPjtE95MJkUDixJHNGj63JT+e6s6p5+PUD/OCl3Zw1N4/kJCk4TkiBFZw6fwnfWTWfL3+4Cotp9r8XfHkLoBmS+vbO+nOL2KGqKiMbfoVJ8dOY9SEqK06Z2ePLlsPAv8ns3hKmCEU0kXaEBBUcsLmgKOOYkpOvf2QONmsyLX2j/Ob1+lmOTsSMwApOnVrM2XPzw5LcAKSWnQRAtrMRfJ6wvIaIfu/u3sfKsVcAyLng1hk/3nbiuQDMc3+Ac8w9m6GJKCQJToLa3joAzGx7aqI0i4n/72JtbMP/bKijpW9kliITMWOkD0Z6AKinOKwnXJdVzsOpWkjCA32SUCeq9lfuI1nx0Ja6EOvCj8z48XlzTmOEZDIVJ/t2vReGCEU0kQQnQQVXcJaUZh3zc3zspCJWVOfi8vq5+yU5hC3hBFZvWtU88nNywnou0vyiTGpV7cA/qcNJTLvr2zjP8QIAlnNvntGBkiFGE62piwDol8GbcU8SnATknTBB/OSDJojPhKIo/OCSEzAaFF79oJMN+7pmKUIREwInGB/wFzOvMCOsL5WbbqHJqLWH9zduC+triei09+8PkKmM0GUuI+/Uy475eUaLTgPA0vHubIUmopQkOAloX+cQox4fGckmqvOOb1thXmEG15xRCcAP/vYBLq9vFiIUMaE7UGCsljCvMPwDWIcy5wHg7ZDVwkTT2NnPGd3PAeBb8Q0wHPtqYdb8swGocO7Ad9BYEBFfJMFJQNtbtNWbJaVTTxCfqZtWziUv3UJDj5PH3mo47ucTMaJnvMA43Cs4AEqBVvOVMrA/7K8lost7L/2GIqWPfmMuRR/+4nE9V+nis/GpCmVKF3UH5HspnkmCk4C2tfQDsKRsZu3hh5ORnMR/XbQAgAfW19F+0Om1IWMO8MsKT7xQgx1U/pKIJDjWiiUA5LhawXOY7zERd7ocI5zS/CQAQ0tvANPRx8ociTHFSou5BoCOna8fd3wiekmCk4DGD/ibvaPKP3lyCadVZjPq8fGjv+859IL29+HeRfDMZ2btNYWO3E6UwRYAGpQSqvPDP7KjqqKKPjUdA/5QciXi31sv/R/VSjtOJY2y82+clecczF+mfdD8zqw8n4hOkuAkmGGXl9qu4ATx2VnBgUDB8SdOxKDAyzs6eLuuZ/yTriH405fAPQT1G8Ar50/EvMAE8V41g8xcW9jOv5loTmEG+9UyAAabdob99YT+HKNuavY9AkDn/C+gJM/Oz6zkmjMAsA2+PyvPJ6KTJDgJZkfrAKoKJVkpFGQkz+pzLyq28oUPaZ0ud764G4/Pr33i5W+Pn13i90Jv7ay+rtBB4ATjA2ox823h354CSE4yYrdUAeBo3h6R1xT6+vcrL7BEqcVNEpUX3Txrz1u+5DwA5vobaO/qnrXnFdFFEpwEcyzzp2bi5vPnk5Nmpq5rmCfeboTtz8KOZ0ExQEaRdlHXFFtYIraE6m+KmVsQmQQHYDR7PgBqp3wPxbsxj4/87f8DQHPFpzBYZ2/mXUpeBZ2GAoyKSuO2DbP2vCK6SIKTYIIH/IUrwclMTeK7q7VfQn/55+v4Xwq86zrnNpi3Wvu4c3dYXltEUPAMHDUyBcZB5qITAMhwyCpgvPv36+s5Q30fHwbKPzaDoZrT1Jl1MgCu+v/M+nOL6CAJToIJjWg4jgP+jubyZWUsK03jp9yHweOEijPh7G9DofbLSVZwYp864Qyc+bbwn4ETlFMV6KTydmpdeSIu+fwq5nceAKCx8HzM+dWz/hqGihUAZPZsnfXnFtEhIgnOgw8+SGVlJcnJySxfvpzNmzcf9tpzzz0XRVEOuV188cWha6655ppDPr969epIfCkxrWNwlE6HC6NB4cTi2SswPpjBoPBw0UucZGigX03n/VN/ph3MFTjHhC5ZwYlpPg/0HQCgUSmhIjf8HVRBc8pL6VBzAPB2yoF/8erNTe9yrudNAIovXhuW1yg68RwA5nv2MDQixw7Eo7AnOM899xw333wzd955J1u3bmXJkiWsWrWKrq6pj/X/y1/+QkdHR+i2a9cujEYjl19++aTrVq9ePem63//+9+H+UmJecHtqfmFGWOcGUftP8ndqnQ+3em5g7fo+vD4/FGgzYBho1jqrRGzqa0DxexlRLaTmVZBkjNxCcGl2CgfQOql6DmyL2OuKyFFVFefrv9LqY7I+REr5yWF5ndyqpQyRSprionaHtIvHo7D/ZLr33nu5/vrrufbaa1m0aBEPP/wwqampPP7441Nen5OTg81mC91ee+01UlNTD0lwLBbLpOuys2fvTJd4FSowDuP2FEOd8MJXABg7+Uu8m7yCvfYhfvdOE6TmQLpNu07OMYldofqbIubYwrcSOBVFUehN0w5pc7ZKq3g8em/3Pj46+ioA2Rd8N3wvZDDQknYSAIP73gzf6wjdhDXBcbvdbNmyhZUrV46/oMHAypUr2bhx47Se47HHHuPKK68kLW3yMviGDRsoKChg/vz53HjjjfT29h72OVwuFw6HY9ItEYW7gwq/H57/f+DshoITSL7ox3z7Aq3g+Jev7adn2AWFgVUcKTSOXcEOKrWE+RGYQXUwT652araxZ2/EX1uEX/urvyJZ8dCauojMheeF9bXcJacDkGI/fNmEiF1hTXB6enrw+XwUFk5u7yssLMRutx/18Zs3b2bXrl18+ctfnnT/6tWreeqpp1i/fj0//elPef3117nwwgvx+aYeA3DPPfeQmZkZupWVlR37FxWjfH41NEE8bAnOf+6H+n+DKQU+/TgkpfDZ08s5scTK0JiXn/5j7/g2lRQax67AGTh1/hLmRrCDKiil5EQAsofrIv7aIrw+aGjj3MG/ApB83i2gHP+svCPJXagN3qwa2YVHBgXHnajuonrsscdYvHgxp59++qT7r7zySj7xiU+wePFiLr30Ul566SXeffddNmzYMOXzrF27lsHBwdCtpaUlAtFHl/2dQ4y4faRbTNTkh+Fdd+sW+Nfd2scX/gQKAu+yDdoJxwB/3NJKo0k7CFAKjWNXaAaVWsx8HRKcwuol+FWFTP8ADMshbfFk78sPkKmM0GkuI2/Zp8L+eiWLzsSDkUKln7pa+ZkUb8Ka4OTl5WE0Guns7Jx0f2dnJzab7YiPdTqdPPvss1x33XVHfZ3q6mry8vKoq5v6HZ3FYsFqtU66JZrg9tRJpZkYZ2GC+CRjDvjzl7RTihddCqdMnva7rCKbTy8rBeDhDwKD8mQFJzb5/aiBFZxmQxllOakRD2FuWSHNagEAw1KHEzeauvo4o/tZAHwrvgGG8L//NlhSabLMA6BrlwzejDdh/Q4ym80sW7aM9evXh+7z+/2sX7+eFStWHPGxf/zjH3G5XHz+858/6uu0trbS29tLUVHRccccr7YHEpwls709parw0regvxEyy+Hj9025rPy18+YA8Hd7JiqKVqcj775jj6MNg2cEj2rEXFAz+8nyNGSmJNEcWAnsrd8W8dcX4bHlxd9gU/rpM+ZR/OEvHv0Bs2Qo/1QADC2bIvaaIjLCniLffPPNPPLIIzz55JPs2bOHG2+8EafTybXXXgvA1Vdfzdq1h55z8Nhjj3HppZeSm5s76f7h4WG+853v8M4779DY2Mj69eu55JJLmDNnDqtWrQr3lxOzwlZgvO0Z2PUnUIzw6ccgZernL89JxWIy4PAl4c2s1O7sknNMYk6gg6pJLaSmUL/OxcEMLWF2te/SLQYxe7oHR1ja8hQAQ0tvAJMlYq+dNvcsAIod21BVNWKvK8LPFO4XuOKKK+ju7uaOO+7AbrezdOlS1q1bFyo8bm5uxnDQUuS+fft46623ePXVVw95PqPRyI4dO3jyyScZGBiguLiYCy64gLvvvhuLJXL/KGKJ0+Vlf6d27szJs5ng9NTC37+jfXzef0HZ6Ye91GhQqMpLY699iIGMOeQPNmgJTvU5sxePCL8JJxjPi9CQzamo+QthECx9+3WLQcyet15+kk8q7Qwr6ZSff2NEX7t8yXnwb6ihhbaOdkqKSyL6+iJ8wp7gAKxZs4Y1a9ZM+bmpCoPnz59/2Ew6JSWFV155ZTbDi3s72wbxq1CcmUyBdZYmiHtd8KcvgccJlR+Gs7511IfU5Kez1z5Ei6mSfJAVnFjUM15gvEiHFvGg9PKToA7yRg9o26Rh7rYR4TM06qZm/6MAdC74PDXJka2RTM4qpNVYSqmvlabtGygpviqiry/CJ6q7qMTs2BaO+pt/fh/sOyAlBz71iDaK4Siq87WzjPb4A236ctR+zPGHpohHdsjmwUpqFuNRjaSpI6iDrbrFIY7fhlf/wknU4cJM1UW36BJDT7Z2WrK7QQZvxhNJcBLArE8Q3/8KvPM/2seXPgTW6RV3BxOc90aCpxnv1Q4HFDFD7dISnDZTGSVZKbrFUW3LpgHt+65HCo1jlsvrI2/bQwA0V1yGIaNAlziMlVrTS16vDN6MJ5LgJIBZLTB2dMALgT3y5TfC/OkPOQ2ev/Of/kwwmsE9DIPNxx+TiAxnL8axPgAMBfNRdNwWSjIaaDdXAdDfuEO3OMTx2bDhn6xQt+HFQMXHwjiW4ShKlnwEgLneWgYdw7rFIWaXJDhxzj44ht0xhkGBxaXHOTfI74Pnb4CRXrAthvN/MKOHV+VpKzidTh++XO3sCTkPJ4YE6m9a1TwqbHk6BwMjWdr3kN8uB7TFIr9fJemdBwBoLFyFOb9Kt1hyShfQr2RiUTzU7XhLtzjE7JIEJ84FV2/mFWaQaj7OmvK3fwUNb0BSKnz6tzNu5cxITqLQqj0m2OYrM6liSKD+5oC/WNf6myBDYK5Z6qB0UsWiuoZ6zvFoyUTxxbfpG4yi0JquDd4c2i+DN+OFJDhxLpjgnHy8E8RbNsO/fqR9fNHPIW/uMT1NdZ62TdUW2F6QFZwY0jOhRTwKEpzsyiUAFLqatNVFEVP669/HqKi0GstILV+qdzh4S5cDkNb5ns6RiNkiCU6c29bSDxxn/c3oAPzpOlB9cOKnYemxt1HWFGjbVPv82ugGaRWPHf4ubXp3nRodKzgVNYsYVc1YcOPqPqB3OGKGxuza99NAaoXOkWjyF2lncs0Z243bIwlzPJAEJ475/Co7W7UJ4sfcIq6q8NJNWjFwVgV87N7jOnMkuIKzZbRYu6NnP3jdx/x8InJ8gQ6qjqTy0FajngqzUqlXtETZXvu+ztGImTL0abMD3Vk1OkeiKVm4nFHMZCtD1O6Rbqp4IAlOHKvrGsbp9pFmNjK34Bjfcb//f7D7eTCY4NOPQ/LxFSqHWsX7U8Fi1QZ09sm776jnGiZpuA0AJV/fDqogRVHoTqkGYLhFOqliTfpwIwBJBfP0DSRAMVloSl4IQO8HMngzHkiCE8eC21OLj3WCePc++Put2scf+R6UnnrcMQVbxZv6RrXj9kEKjWNBb632HzWDouJSnYMZ585ZAIAitVwxRVVVCj0tAGSWLtI5mnEjhdrPOFObDN6MB5LgxLHx82+OYSiiZ0wbxeAdherz4IxvzkpMJVkpWEwG3D4/w5mBQmX55RT9Js6gKtBvRMPBzMUnAGAdqtM5EjETPf0DFNMDQEH1iTpHMy5j3ocBKB3aIYM344AkOHFsW4tWf7O07Bi2lV67HTp3QWoefPI3YJidbxVDYOgmQLsl2EklhcZRr2dCi7iOQzYPlle9FACbt1WbjyZigr1BW7UdJJ3kTH1OL55K+ZJz8asK5dhpaW7UOxxxnCTBiVMjbi/77A7gGFZw9v4dNv+v9vEnfwMZhbMaW3Cbqo5y7Q5JcKKerzM4ZDM6WsSDqqrm4lBTMeFjoEW+j2KFo1X7u+oyl+scyWSW9GyakyoBaN3xb32DEcdNEpw4tbNVmyBusyZjy5zBBPHBNvjrV7WPV6yBuStnPbaaQKHx1rHATKr+RnDJ8ejRzNOptfR2WSrIS9e/gyooLTmJRqPWZtxVJ51UscLXpdV0DadX6hvIFHpzTgHA17hR50jE8ZIEJ05tbx0AZnj+jd8Hf7kBRvuhaCl89M5whEZ1YAVnZ38SpAdWhwKn5Ioo5PNgdjQCoOZFR8fLRP1pWpvxSNsunSMR02Ue0Don1dw5OkdyKEv1GQDk90vCHOskwYlTwQLjGZ1/8+a90PQWmNO1lnCTOSyxBVvF67uHoSDQQdElnVRRq68eg+rFqVrIK67WO5pD+ALdeEm9e3WORExX1mgTAClFC3SO5FBlS7XBm3N8B+jr79c5GnE8JMGJU9uaB4AZrOB43fDWf2sfX/QLyA3f4VvBFZyeYTeunPnandJJFb2CM6jUYubarDoHc6jUUq0LJ8cp5ynFAq/XR6lPO1Mpt+IEnaM5VKatmi4lD5Pip377G3qHI46DJDhxqMsxRvugNkH8pOlOEO/YDh4npOTAkivDGl+6xRQ6CdeeHFgRkLNwolfPeIHx/CjqoAqyzTkZgCK/Hd+Y1HJFu/a2JtKVUXyqQl5Z9K3gAHRYtTlnI3UyWTyWSYIThyZOEE+zTHOCeNPb2n8rzjiuUQzTFeqkUoKdVLKCE62CBcZ1/mLmHeuJ2GFUVlpOt6ol8nYpNI56PY1arVSn0YbBPIMGiAjyl30IAGuXDN6MZZLgxKFQ/U1p1vQf1PQf7b8VZ8x6PFMJ1uHsGLMBCji7wNkTkdcWM+MJDEXsSakkMzVJ52gOZTQotJkrAehr2K5vMOKonB3aimB/cnS1iE9UcOK5AMxx7WHMJbPyYpUkOHEodIJxedb0HuD3QfM72scRSnCCKzh7+3yQXandKefhRB+/P9TxQhR2UAU5MrTY3B2y1Rn1erQW8bHMKp0DObziuacwTCrpyigHdm3WOxxxjCTBiTM+v8qO1uAJxlnTe1DnbnANgjkDCheHL7gJgoXG9d3O8U6qTklwoo6jFZNvFI9qJLN4vt7RHJZSqH0PpfTLcQPRLm2oAQBDfvQmzIrRRFOKVgDdu1cKjWOVJDhxpr57mGGXl5QkI3OnOzMouD1VvhyM06zZOU7VgXENjb1O/MGhm7KCE30CM6gaVRtzirL0jeUIrBUnAVAwVq9zJOJo8lzNAGSULNQ5kiMbLToNAEu7rODEKklw4sz7ge2pxaWZmIzT/OudWGAcIcGhmx6fSk/goDYpNI5CoQ6q4qga0XCw0nlaJ1We2o+zv0vnaMThDDmdFKva309hFA3ZnErWfG3wZoVzB36/DN6MRZLgxJlg/c3J092eUtUJBcZnhiWmqUwcullv0I7ap2uPFo+IGq5AgXGdWsLcKE5wcnNyaUMb2thWu1XnaMThdNTvwaT4cZJMRl6Z3uEcUcVJH8ajGrHRS3ODbH3GIklw4sz2YIHxdBOcnloY6QFTMhSfHLa4plIT2ELbNZoHhiRwD8FgS0RjEEfm6tBW1fpSKkmf7pEDOulK1opWHU07dI5EHE5/i1YEbjeVReQ4iuORlJJBk1lbXe6QwZsxSRKcODLq9rHXPgTMYERDcHuq9DQwRXaIYk1gBedAnwvyAwWsUmgcVcz9dQCoudFbEBo0kqXFqMr3UNRyd2o1XY60Sn0DmaaBvGUAqMEuUxFTJMGJI7vaB/H5VQoyLBRNd4J4hM+/mSi4gnOgywkFUmgcdZy9JHu0WTzpUV4QCmAq0mo60h21OkciDsfUrx054M0O3yiY2WSp0bbtCwa36RuIOCaS4MSRifOnlOks/6qqLgXGQdV5gVbxnolDNyXBiRqBAuNWNY+q4gKdgzm63CrteP1idwOq369zNGIqmSONAFhs0XvkwEQVgcGb1b4merqleD3WSIITR7a1DgAzOOBvoBkcbWAwaVtUEVYVOM24Z9iNMzOwBSKdVNEjMGSzzl8S1R1UQaVzT8KrGsjESY+9We9wxEFUVaXI0wpAdvkinaOZHmteCW2GIgyKSuM2qcOJNZLgxJHQCs50RzQEt6eKTwZzWlhiOpJ0iwmbVdtKazAFOqm694HPE/FYxKFGAwXGdWoxc6Z7ppKOklPSaDMWA9C+f4vO0YiDdXV2kK1oNYKFldE3Rfxw7Jla88VY/X90jkTMVEQSnAcffJDKykqSk5NZvnw5mzcf/uCkJ554AkVRJt2SkyfXk6iqyh133EFRUREpKSmsXLmS2trE3nfvHnLRNjCKomhn4ExLs371N0HBmVR7R7K0k5T9Hug9oFs8YtxYu7Zd2J9aRYrZqHM009ObqtV2OFt26RyJOFhXw04AOpU8zKnRvyIYZKjQBm9m9UjSHGvCnuA899xz3Hzzzdx5551s3bqVJUuWsGrVKrq6Dr+fabVa6ejoCN2ampomff5nP/sZ999/Pw8//DCbNm0iLS2NVatWMTY2Fu4vJ2oFz7+ZW5BORvI0ByLqcP7NwYIzqQ70TCw0lnlC0SAp0EHlj+IZVAfz5Gi1HcYe2eqMNkNt2plKvZboPv/mYLbg4E33XkZHR/UNRsxI2BOce++9l+uvv55rr72WRYsW8fDDD5Oamsrjjz9+2McoioLNZgvdCgsLQ59TVZVf/epXfO973+OSSy7hpJNO4qmnnqK9vZ0XXngh3F9O1No+0wniQ53QWwcoULY8XGEdVXAFp757eEKCI7+cdOcaJn2sA4DU4tiolwBILtVmqWUN1+kciTiYPzBkcyQjeodsTsVWvZgBMkhWPBzYIdtUsSSsCY7b7WbLli2sXLly/AUNBlauXMnGjRsP+7jh4WEqKiooKyvjkksuYffu8Xf0DQ0N2O32Sc+ZmZnJ8uXLD/ucLpcLh8Mx6RZvZjxBPLg9VXgipEzzMWEQWsGRoZvRpVf7ZdSjWikvLdU5mOkrqFkKQJm3GY/Xq28wYpKUwcCcsBhaEQRQDAaa07TEeXCfDN6MJWFNcHp6evD5fJNWYAAKCwux2+1TPmb+/Pk8/vjj/PWvf+V3v/sdfr+fM844g9ZWrfo++LiZPOc999xDZmZm6FZWFltLpEfj96szP8FYx/NvJgqu4DT1OvHJ0M2ooQY6qA5E+QyqgxVWLMSlJpGquGht2Kt3OGKCnDGtsy21eIHOkcycq/h0ACwd7+ociZiJqOuiWrFiBVdffTVLly7lnHPO4S9/+Qv5+fn85je/OebnXLt2LYODg6FbS0t8jQOo7xlmyOUlOcnA/On+MoqSBKc4M4XkJG3oZqs5sHTd3whup65xJTpnm5ZkHlBLQkloLDCYkmhL0t7AdNW9r3M0IsjldlPs17Y8C2KogyooZ+E5AFSP7sTvkzOWYkVYE5y8vDyMRiOdnZ2T7u/s7MRms03rOZKSkjj55JOpq9P21IOPm8lzWiwWrFbrpFs82dYyCMDikmlOEB/pg87Atp/OCY42dFPbpqobtkBaAaBCt7z71tNYu1YH1Z9ahcUUGx1UQYMZcwFwtUuxerToaNqHRfEypiaRWxIbpxhPVHHCClxqEjk4aKzdqXc4YprCmuCYzWaWLVvG+vXrQ/f5/X7Wr1/PihUrpvUcPp+PnTt3UlRUBEBVVRU2m23SczocDjZt2jTt54w321q04/SnvT3VsglQIXcupOt/Qu14ofGETiqpw9GVqU+rwfHnztU5kpnz52lbIOY+SZKjRW+T9u+5w1SCYoithBnAZEmhwaJ16Nl3bdA3GDFtYd+iuvnmm3nkkUd48skn2bNnDzfeeCNOp5Nrr70WgKuvvpq1a9eGrr/rrrt49dVXqa+vZ+vWrXz+85+nqamJL3/5y4DWYXXTTTfxwx/+kBdffJGdO3dy9dVXU1xczKWXXhruLycqhQqMy7Kn9wAdxzNMZbzQeBgKA8vX0kmlH5+HjBGtXiI5hjqogtLLTwIgb6Re50hEkMuuJZsDqRU6R3LsHPna4E1DiwzejBWmcL/AFVdcQXd3N3fccQd2u52lS5eybt26UJFwc3MzBsN4ntXf38/111+P3W4nOzubZcuW8Z///IdFi8Z/0N566604nU5uuOEGBgYGOOuss1i3bt0hBwImgjGPj70d2umg0+6gioLzbyaqmbiCUyWFxrrrq8eIj2E1mZLyOXpHM2NFc06B9VDub2VweITM9FS9Q0p4hl6txMCdFXvbU0Gpc8+CticpdmzTOxQxTWFPcADWrFnDmjVrpvzchg0bJv3/f//3f/Pf//3fR3w+RVG46667uOuuu2YrxJi1u30Qr18lL91C8XQmiLuGoX2b9nE0ruAUBFdwJMHRi79rLwYCHVS22OmgCrLaqnCSTJoyxr66nSxeqt85T0KTPtwIQFJBbLWIT1S59COwAcrVdrrsrRTYYuf4hEQVdV1UYmben+kE8dbNoPogsxyyoqNdvipPW8HpdboZSA90Ug13grNXx6gSl6NVK85toISK3NjpoApRFDoCHXn9Ddv0jUUAUOjROlczS2NvyzMoPSuPRmM5AM0yeDMmSIIT44L1NyfPeHsqOlZvANImDN08MKhAdqX2CVnF0cXEDqqk6XTlRSFnlrZS4LXL95DeBvv7yEdrhLBVL9Y5muPTnaUN3nTXv61zJGI6YvOnlwjZ3joAzGBEQxQmOAA1BRNHNgTe5UmhsS6MvfsB8ObEXgdVkKFQ+x5KHdivcySiIzBks5cs0jJzdI7m+BgrtZ+bOX1yxlIskAQnhvUOu2jp0yaIn1Q2jQniXhe0vqd9HCUFxkHVgbNw6nsmjGyQoZuR5/djdTYCkFK8UN9YjkNWxRIAbGMNqKqqczSJzdGivVHpMkfHlvjxKF1yLgDVnlqcw/E38ifeSIITw4LbUzX56VinM0G8bSv4XNphernR1c0Q7KQ60CVDN3XlaMWijuFWjRRUxG6CY5urbSWUY6etu0/naBKbt0sb+zGcXqlvILOgoGw+3eRgVnzUb39T73DEUUiCE8O2zXj+1ITzb6ZTkBxB1fkTVnAmnoUj774jyhf4ZdSo2phXNM1zlaJQkrWQAcWKQVFpq92udzgJzRIYsunPjb0jBw6hKLRkaKuDQ/vf0jkYcTSS4MSwYIKzZMYDNqNrewqgpkBLcJp6nXizqsGQBC4HDLbqHFliGWjeBUA9JZTlxPD5MYpCd0o1AI5mSXD0lDmqHRqZYpuvcySzw1dyGgBpnTJ4M9pJghOjJk4QP3k6CY7PGxjRQNQVGAMUWZNDQzdbHF7IC5yXIZ1UETUSGLI5kFaF0RBdq3wzNZYd+IUqW5268ft8FHvbAMitiL0hm1PJXXQuAFWju/H5fPoGI45IEpwY1dDrxDHmxWIyMH86h7HZd4B7GJIzx4t4o8jEoZuT63AkwYmkUAdVdux2UAWZi7VfqNahOp0jSVydbfWkKi48qpHC8vhYwalYdDojqgWrMkLDnvf0DkccgSQ4MWpb4IC/xSWZ0zurJLg9Vb4CDNH51x4a2dAzLEM3dWJ1avUSlhicQXWwvCqt0LjM08iYR95p66G7UeuE7DDaMJktOkczO4ymJOpTtOS5Z/frOkcjjiQ6f9OJowqdfzPj+pvo254KChUadztl6KYenD2k+xz4VYX8ytjfTsip0g6VK1Z6qW9t1zmaxDTSrg3Z7EuO3SGbUxkuOBUAY+smnSMRRyIJToyaUQeV3w/N0VtgHBRqFe+esILTsw98Hh2jShzeTi2ZbFPzmFNSoHM0x09JyabHkAdAZ902fYNJVL21AIxlVukcyOzKmHcWAKVDUsAezSTBiUFjHh97OrRDpqaV4HTvhdF+SEqFoiXhDe441ExcwcksB3M6+NzQV69zZImht1HroGpQSijJStE5mtnRn6a1Jo+27tQ5ksSUOtQAgDEvdodsTqVqydl4VQNFdNPRckDvcMRhSIITgz7ocODxqeSmmSnNnsYvouD5N2Wng3EaBwLqZNLQzTEv5C/QPtEpJxpHQrCDqj+1anqDW2OAN0/7HjL17tU5ksSUP6a1iKeXxu6hkVNJzcimIUk7hqBtxwZ9gxGHJQlODNo20wniUXz+zURpFhNFmYGhm91OKJSZVJGkBDqoPHHQQRWUUnoiANlOeZcdaWMjwxSqPQAUVp2oczSzr9+qJc8eu/x8ilaS4MSgGdXfqGpMFBgHVU+qwwkmONJJFQnW4UAHVVH8vNsurNE6qar8zfQOu3SOJrF0NOzGoKgMkkZ2XpHe4cw6f7Y27iZpQLbQo5UkODEolOCUZx394r56GLaD0Qwly8Ia12yYVIcjCU7kuIbJ8XYBkFu5WOdgZk9K8SL8KOQpDuobG/QOJ6H0N2v/bjtMZShRejTF8UgOnMycOdKkcyTicOLvuy7O9TndNPeNAHBSadbRHxBcvSlZBknRXzhanTfFCk5fA7hHdIwq/rk7tRqVbtVKTUXsT30OMafSbSoGoKdeOl4iyW3XvqeG0uKrRTwou0xb6SzytqH6/TpHI6YiCU6MCY5nqM5PIzNlGgXDMbQ9BeMzqeq7hyE9H9LyAVXrBBNh092gdRk1KqUUZMTHgWxBDqtWU+Rul06qSDINaHVP3sBWTryxVS7ApyqkK6P0dMnMvGgkCU6Mef94JojHgOBhf819I3h8/gkjG6SQL5ycbVqnWn9KZdx0UIUEVgJT+vfrHEhisTq1rRtLnAzZPJglOZVOg3ZeVHejbKNHI0lwYsy2mQzYHGyDgSZQDFC2PKxxzZYiazIpSUZt6GbfCBQETzSWHyDhpHRrv/xdcdRBFZRRrtUUFYzV4/OrOkeTGFS/H5tXW9XIKo/9sR+H02PRtnOH22SFORpJghNDVHV8gvi0RjQ0b9T+W7QELNMYyBkFtKGbgZlU3U4Zuhkh6XHYQRWUH+ikmkMLzb1OnaNJDP3dbVgZwa8qFFfF/tiPwxnNqATA11OrbyBiSpLgxJDG3hEGRz2YTQYW2KxHf0Boeyq6z7852KRW8eBMKhm6GT5eN/meNgByKuLvvBJj3hw8mEhXxmg8IO+0I6GzQTsVu8NQQHJKms7RhI+ao9UXJTsa9Q1ETEkSnBiyraUfgBOLrZhNM5ggHiP1N0GTWsXzA/v3w3YY6dMxqvg11lmLCT9DagqVVfG3RYUxiR5LOQCDTTt0DiYxOANbNsEtnHiVWqT9fMoebdY5EjEVSXBiyPaWQWCa21POnvHOo/IV4QsqDCat4FgyIEv75STbVOHRWa/90m9SSsjLSNY5mvBwZmmzkPwy9iMifIGarpGM+BqyebC8Cm2FucjXgd/n0zkacTBJcGLIXrs2YPPE4syjXxysvylYBKk5YYxq9oVWcHoC9RKhQmPppAqHoVbtl35vSqW+gYRRUpH2PZQ+KLUSkZDs0Gq6lDgbsnmwwrI5uFUTFsVDZ2ud3uGIg0iCE0MaAr/wg2fFHFGMbk/B+ApOn9NNv9M9Xmgs777DQunZB4A7a47OkYRPduUSAEo8jYy4vTpHE/9yA0M2U4sW6BxJeBlNJjqM2hiKniZZYY42kuDECKfLS6dDm6VTlTuNor1ggXGMbU8BpJpNFAeGbtb3TCg0lhWcsEgb0t5tJ9nir4MqyFp+EgBzlHb2dwzoG0yc87rHsPnsAOTFcQdVUF+yVmc00rFP50jEwSTBiRHB1ZvcNDOZqUc5wXhsEOyBU1tjcAUHxg/8OzCpVXyPNjxUzB6/H5tbe7edUxl/HVQhWRWMKRYsioe2A7ISGE6dTXsxKX6cajK24viuwQEYswa+xl7Zooo2kuDEiGCCEzwj5ohaNoPqh+wqsBaHObLwmFRonDsXDCZwDYKjTefI4stwVwPJuHGpJipq4vjdtsFAb0o1AMMtMrIhnPoCWzXtphIMxvj/FWPM07Z2pVU8+sT/d1+cmFGCE6Pn30w0qVXcZNaSHJBtqllmP6ANoGw1FJGZHv3DWI+HO1dr6TX0yPdQOI0GhmwOpJTrHElkpBVrdUZ5rhadIxEHkwQnRoQSnPzpJDixW2AcNGkFB6AwcNy7FBrPqqGWQAdVcqW+gURAcrE2siFrqA5VtjrDxtCnbdW4s+JzyObBCiq1lU+bvxO3a0znaMREEUlwHnzwQSorK0lOTmb58uVs3rz5sNc+8sgjfPjDHyY7O5vs7GxWrlx5yPXXXHMNiqJMuq1evTrcX4augi3T1UdbwXGPQNtW7eMYTnCCKzjNvTJ0M5zUHu28krE47qAKyq3WOqmq/M10Dbl0jiZ+pQ83AmAqiO8W8aA8WxlONRmjomJvkpOyo0nYE5znnnuOm2++mTvvvJOtW7eyZMkSVq1aRVdX15TXb9iwgc9+9rP8+9//ZuPGjZSVlXHBBRfQ1ja59mL16tV0dHSEbr///e/D/aXoRlVVGgIrGVV5R2kRb3sP/B7IKIbsyvAHFya2wNBNr//goZuygjOb0hwHAEgqjO92XgBzkVZEXanY2dfWo3M08avQrW3VZJbG75DNiRSDgQ5TCQD9zfIGLJqEPcG59957uf7667n22mtZtGgRDz/8MKmpqTz++ONTXv/000/z1a9+laVLl7JgwQIeffRR/H4/69evn3SdxWLBZrOFbtnZ2eH+UnTT53TjGPOiKFCRm3rkiyduTylK+IMLE4NBmbBNNaGTqns/+OQck1mhqtjcTQBkx+EMqkNk2HAaMjApfjrrpdA4HJwD3WSjHUhaVJ0A31MBA6lavdGYXVrFo0lYExy3282WLVtYuXLl+AsaDKxcuZKNGzdO6zlGRkbweDzk5Ew+jXfDhg0UFBQwf/58brzxRnp7ew/7HC6XC4fDMekWS4L1N8WZKSQnGY98cRzU3wRVhwqNhyGrApLSwOeCvnqdI4sPgz3tZDKMX1UonbtE73DCT1EYSNe24lxtu3QOJj7Z67U/105yyMyK3zedB/NYtQ49pe+AzpGIicKa4PT09ODz+SgsLJx0f2FhIXa7fVrP8d3vfpfi4uJJSdLq1at56qmnWL9+PT/96U95/fXXufDCC/EdZhbIPffcQ2ZmZuhWVhZbA+BC9TdHKzD2urUWcYjpDqqgYL3Rge5hMBigILCNIjOpZkV7ndZB1WEoID09Q+doIsOfr30PJfVJrUQ4OFq1LZouc2z9jD1epnwtcU4bbtI5EjFRVHdR/eQnP+HZZ5/l+eefJzl5fAjglVdeySc+8QkWL17MpZdeyksvvcS7777Lhg0bpnyetWvXMjg4GLq1tMRWO9+0W8Q7toN3FFJzx6dwx7DgSIr67uBMqsCeviQ4s8IR6KDqSa7QOZLISS/TTjTOH6nXitfFrPJ0aVs0Q+nxf8DfRBmlWuKc746t3y3xLqwJTl5eHkajkc7Ozkn3d3Z2YrPZjvjYX/ziF/zkJz/h1Vdf5aSTTjritdXV1eTl5VFXN/VJkhaLBavVOukWSxq6p5ngTBzPEMP1N0GTVnBAEpxZ5u/WfhmNZcZ/B1VQZoX2s2QuLaE3DmL2mAe07WM1J3G+pwBsgVbxAvoYHY6tEoh4FtYEx2w2s2zZskkFwsGC4RUrDj8j6Wc/+xl3330369at49RTTz3q67S2ttLb20tRUdGsxB1tpr2CE6q/if3tKRjfkusf8WhDN0Nn4UiCMxuCHVSmBOigCjIEvofKDN3Utkxvm1xMX/aotkWTXBT7K8gzkZVXSD/aNm9Ho/x8ihZh36K6+eabeeSRR3jyySfZs2cPN954I06nk2uvvRaAq6++mrVr14au/+lPf8rtt9/O448/TmVlJXa7HbvdzvCw9i5+eHiY73znO7zzzjs0Njayfv16LrnkEubMmcOqVavC/eVEnN+v0tAbPAPnCC3ifh80v6N9HAcFxjDF0M3gCk5fPXhGdYwsPhS4tF9GWYnQQRWUmoPDlAtAX8N2nYOJL6rPi83bDkBuRRyP/TiMTlMpAAMt0ioeLcKe4FxxxRX84he/4I477mDp0qVs27aNdevWhQqPm5ub6ejoCF3/0EMP4Xa7+fSnP01RUVHo9otf/AIAo9HIjh07+MQnPsG8efO47rrrWLZsGW+++SYWiyXcX07EtQ+O4vb6STIqlGQf4Sj9zt3arCZzBtgWRy7AMAvW4RzockJavlZfhArdUiR6PHr7erGhdR4W1yzVN5gIG87Uxn547fJOezb1ttVhUTy41CSKyufqHU7EOdK0WjZ3536dIxFBpki8yJo1a1izZs2Unzu4MLixsfGIz5WSksIrr7wyS5FFv+D2VEVuGkbDEepqgttT5R8Cw1FayWNIdV4ab9b2cKBnWKsrKlgEjW9qJxoXn6x3eDGrbf92coFeJYvczFy9w4kopWAR9L5D6oD8IppN3Y27yQPaDEVUm816hxNxvqxqGARTv7SKR4uo7qISM6m/CQ7YjI/tqaDgWTgHug7qpJKZVMdlsEU7r6TbkjgdVEGZFdqZP8XuBhxjHp2jiR/Odm1rpi9BhmweLKlQW7XKGGnWORIRJAlOlAu2SB9xBpWqxtUBfxOFpor3HDR0U2ZSHRdfoJ13NIE6qIJSS7Ut3PmGVvbZh3SOJn4ovVoX61jg0LtEk1WqnbZe6GnVORIRJAlOlJvWCk5PLYz0gCk57rZtgp1U40M3pVV8NqQGOqiMBYnV7QKEzogqUAZoaJZ327MldagBAEN+4tXfABRVaT+bshjC0dd5lKtFJEiCE+WmleAEt6dKTwNTfBVa26zJpJq1oZvNfSMQOImWoQ4Y6dM3uBilqir5rkYAMssTqIMqyJLOgKUYgMGmHToHEz/yXFqymF6yUOdI9JGWkUknWj1bZ4NsoUcDSXCimMvro7V/BICqI41piNPtKdCGbgaTu/puJyRbITOwxy+dVMeks3+IMlV7h2mrOfIhmvFqNFtbxVFkq3NWuJ2D5KvaG47Cqvjp4pypbrPWKu5ok6Gb0UASnCjW0jeCX4V0i4n89MOszKhq3BYYBwXrcEInGhdKofHxaKnbiUnx4yQFS3ap3uHoIqlI+x7KcNSiqqrO0cS+4IpFr2qloKDwKFfHL2d6JQCeLunQiwaS4ESx+gkjGpTDjV4YaAZHGxhM2hZVHArW4dSHRjYElsDl3fcxGWzWOqi6LBVxMdLjWGQFOqmq1GbaBuTQyOM1EBiy2ZFUevifVQnAl10DgHmwQedIBEiCE9WmV38T2J4qPhnMR2klj1GhVvHQ0M3AKalSaHxMfJ3a8vlIZo3OkejHZNO+h+YrLextl9lBx8tl17aLHWmV+gaisxSbVmCdKa3iUUESnCg2rQSnOX7rb4JqDruC84G2RSdmJNmhtfMaCxJnBtUh8ubiw0CmMkJrS73e0cS84OF23qzEO3ZgouwybeuzyNuK6pdp9XqTBCeK1QcSnOppFRjHx4DNqQQTvP4RD31ON+TN07bkxgbB0a5zdLHF71cpGNNmUFnLEm9eUIjJwmCqdsihs0U6qY6X1dkIgMU2T99AdFZUNR+vaiBVcdHX2aJ3OAlPEpwodtQVnKFO6K0DFChbHrnAIizVbKIkS5vDVd89DCYz5AbeKUodzoy09TupREsK86sSs4MqyJurrWCZeqQb77ioKjZvGwBZiZw0AxZLCh0Grci6q1GaIPQmCU6UGhrz0D3kAqDycAlOcHvKdiKkZEUmMJ2MFxofNLKhS36IzERz/V5SFDduTCTlVukdjq5SSrUzgHJH6nF5fTpHE7scXc2kMoZHNVJclcDbngF9Fq0z0dkureJ6kwQnSjX2aOff5KVbsCYnTX1RAmxPBR3SKl4gIxuOxUCzlhD2mMvAGJFZu1ErvUw7r2Wu0kJd17DO0cSursadALQrhWSkpeocjf5GMioB8PXU6huIkAQnWgVnLx1xBlUcH/B3sOAKzngnVaDQWM7CmRFvp7Yd47QmbgdVkBLoxpuntLK3fVDnaGLXcKBFvMdSpnMkUSKwfZ4sreK6kwQnSh21/makb/yXe3kCJDh5gaGbBx/2170P/LK9MF3Jg1oHlSERZ1AdLKcKj2ImRXHT2SzbCcfKH1ipcGYk9pZnUGqg0DprTIqM9SYJTpQKJTiH66Bq2QSoWkdRen7kAtNJTUFg6GZfYOhmViUkpYLPBX3S5jsdPr9K/lgjANbSxC4GBcBgZChDW8lyte/SOZjYlTyo/ftT8hJzyObB8iq0f1tFvnb8Xq/O0SQ2SXCi1FFXcOJ8PMPBJg7dbOodAYNhfPCmHPg3Lc29TqrRul1yKhN3XtBEamCrM6VPVnCOVU7g2IHUIikwBigsq8GlJmFWfHS11ekdTkKTBCcKqapKQ6DW5LA1OAlUYAygKMoUIxuCM6kkwZmOxuZGshQnfhSM+fJuGyC9TGuVL/E0MDDi1jma2ON3jVDg6wYgryoBJ9NPwWQy0WbUptX3SKu4riTBiUI9w26GXF4UBcpzp+hKcA1D+zbt4/IVEY1NT6E6nMDqVqgOR1ZwpqU/0O3Sl1QESSk6RxMdLMXaL+V5Sut4h56Ytu6WvRgUFYeaSkmxFBkHDSRrfxYjHbIyqCdJcKJQcHuqNDsFi8l46AWtm0H1QWY5ZCXOD5VQq3jXFCMbxFF5AjOonNZqnSOJIoFtzmqlg3r7gL6xxKC+Jm2Fos1Ygmmqn1UJaswaKLjuPaBvIAlOEpwo1BBoEa8KrFgcIoHawycKbVH1HDR0s68ePDIR+mgsA4FzOfKlgyoksxSXIZUkxUdfq5xoPFOjdi1p7k+t1DeQKGMIFFynDkmruJ4kwYlCoRlUR62/ScwEJ7SVkF4AKTmg+qFnv46RRT+Pzx/qoMqQDqpxisJQuvZu22uXBGemDL1aEa07S1YFJ0or1lrFc1ytOkeS2CTBiULBAuMpO6i8Lmh9T/s4QQqMg4I1OAPBoZuKAoWBX9ZSaHxEjT1OqhVtBlV2uRSDTuQPvNs2D0jHy0ylD2srFKb8xB6yebDCSu3nks3fhcclq8t6kQQnCh2xRbxtq3b2S1oB5CbWabQpZmNo6Ob4yAapw5mO+lY7RUofAIpsUU2SWqx9D+WNNTHmkUMjp01VKXRrh9llli3SOZjokm8rZUhNwaCo2BtlnIxeJMGJMr7gOS8cJsGZeP6NokQwsuhw2FZxSXCOqLdJO8jOYcqJ+8GsM5VWrH0P1ShtNPY6dY4mdowNdpKBE7+qYKuUBGcixWCgw6QN3exvkZ9NepEEJ8q0D4zi9vkxmwwUZ03Ryptg598cLNhJdehUcXmXdCQeu/bnM5yRWKt+06EEOqlqlHYOdA7pHE3s6GrQkuZ2JY+87Eydo4k+gylah+uoXYZu6kUSnCgTLDCuzE3FaDhohcbnDYxoIOEKjINqDi40Dm5ROdpgtF+nqKKfOdhBlSe1EofIqcKHkTTFRWeLjP2YrsHAykR3UhlKAq4mH40nUHht6JNWcb1IghNlGrqDLeJTbE/Zd4B7GJIzx1cuEkz1wSs4yVbIDJwF1CVdMFMZ8/jICxynny4dVIcyJjGYWg7AmF22E6bL26V1Lg6lV+obSJQKnhaePtyobyAJTBKcKDNeYDzFGTjB7anyM7RZTAkoWIPT1DeC2+vX7gxtU8mx6FOp73ZSE5hBJS3iU/Nka7+MjL2ynTBd5gFtZcKfM0fnSKKTtVRbXc53y1RxvSTmb8kodtgzcIa7YNNvtI8rE7P+BsaHbvr8Ks19WjH2eCeV1OFM5UBHLxVKJyAdVIdjsWl1OJnOBvx+VedoYkPWqLYqmFwk31NTsVVpbybyGGBseEDfYBKUJDhRJrSCkz8hwfGMwrOfg8FmyKmGkz+vU3T6mzh084AM3ZyW3uY9GBWVMUMaZNj0DicqZZRq30NVtNI2IOeWHJXPQ4HPDkCOnKs0pazsXHrRiq87GmR1WQ8RSXAefPBBKisrSU5OZvny5WzevPmI1//xj39kwYIFJCcns3jxYv7+979P+ryqqtxxxx0UFRWRkpLCypUrqa2N/aXlMY8v9MM1VIOjqvDXr0Hru5CcBZ/7I6Rk6xdkFDikk2ri0E1V3n0fzB04odeRXpWQRwtMh7FwQieVDN08qoH2WpLwMaJaKKuQzrypKIpCZ6BVfLBFVpf1EPYE57nnnuPmm2/mzjvvZOvWrSxZsoRVq1bR1dU15fX/+c9/+OxnP8t1113H+++/z6WXXsqll17Krl27Qtf87Gc/4/777+fhhx9m06ZNpKWlsWrVKsbGxsL95YRVc98IqgoZySZy08zanRt+Arv+DAYTXPF/kCf73cETjUO/iPLmgWKEsQEY6tAvsChl7NdqJVSplTi8QHdZnuKgta1N52CiX09gMn2roZgUS5LO0USvoTSteN3VFftvwGNR2BOce++9l+uvv55rr72WRYsW8fDDD5Oamsrjjz8+5fX33Xcfq1ev5jvf+Q4LFy7k7rvv5pRTTuHXv/41oK3e/OpXv+J73/sel1xyCSeddBJPPfUU7e3tvPDCC+H+csIquCJRnZemtV3u+CO8/hPtkx/7FVSdrV9wUaSm4KDD/kwWyA388pYD/yZxe/1kB2olUosX6BxNFDOn4TBr23fDbbKdcDTOdm1VsDe5XOdIops3W1vdMvXL8QN6CGuC43a72bJlCytXrhx/QYOBlStXsnHjxikfs3HjxknXA6xatSp0fUNDA3a7fdI1mZmZLF++/LDP6XK5cDgck27RaNKIhuZN8Nevap8485twyhd0jCy6jK/gOFGDW1LBQmOpw5mkqddJlaKtaqWXLNQ5mug2mhVIkmVw69H1aHO7xqwyZPNIzAVad57V2aRzJIkprAlOT08PPp+PwsLCSfcXFhZit9unfIzdbj/i9cH/zuQ577nnHjIzM0O3srKyY/p6wq2hR1uRWJI+qBUV+9yw4GPw0e/rG1iUCdYnDY4Ghm7CeKFxt5yFM1Ft51BoyKaSK1tUR2Is0LqB0h3ybvtoUoe0IZuGwFkvYmpZgRldhd5WqQ/UQUJ0Ua1du5bBwcHQraUlOs8laOhxksEIl+27GUZ6oGgJfOp/E/bMm8OZOHQz2FZPYCI0PbLXPVFrWyuZygh+lIQbzjpTwU6qEm8z/cHEWUwpz9UMQHppYh44Ol1FVdqqqRUnQ/2dOkeTeML6mzMvLw+j0Uhn5+S/2M7OTmy2qdtVbTbbEa8P/ncmz2mxWLBarZNu0ai528GDSfdhHToAGUXw2WfBPMWJxmK8VbwrWGgcSHB663SKKDoNt2vdG85kGyRNMdtMhFhs2i+jOdJJdUS+kX6y1UEACivl4MgjSU/PoIM8ADobdh3lajHbwprgmM1mli1bxvr160P3+f1+1q9fz4oVK6Z8zIoVKyZdD/Daa6+Frq+qqsJms026xuFwsGnTpsM+ZywYHHGzxvUIZxt3oialasmNtVjvsKJWqFU8uIKTE1idGO2DkT6doopCgVoJT6bUShxV4BDEEqWHRnu3zsFEr+7AmS6dajZFBfk6RxP9us1aSYSjVbbPIy3sex8333wzjzzyCE8++SR79uzhxhtvxOl0cu211wJw9dVXs3bt2tD13/zmN1m3bh2//OUv2bt3L9///vd57733WLNmDaCdLXDTTTfxwx/+kBdffJGdO3dy9dVXU1xczKWXXhruLydshl//NV8w/RM/Csplj0LxUr1Dimo1B6/gmFPBqp05IdtUGq/PT7pTq5VIKpTTZo8qLY8RYyYGRWWgWYrVD6evRUtwOkylhw4EFodwplcA4OmW1eVIM4X7Ba644gq6u7u54447sNvtLF26lHXr1oWKhJubmzFMqDE544wzeOaZZ/je977Hf/3XfzF37lxeeOEFTjxx/LTMW2+9FafTyQ033MDAwABnnXUW69atIzk5OdxfTnjsf4XiTXcD8HTGdXxhwcU6BxT9DlnBAe2MIEertk1VvlynyKJHS/8olapWYJwmLeLTMmytJrX/fXxd0kl1OB77PgAcaZX6BhIj/Dk10AfmQSlej7SwJzgAa9asCa3AHGzDhg2H3Hf55Zdz+eWXH/b5FEXhrrvu4q677pqtEPVj3wV/+hIKfn7vPY8PKq/WO6KYEJwq3hwYumk2GbSzcOo3gAxMBLQOqipF6yw0yAGR06Lmzof+97EMyLvtwwkeHBk840UcWbJtPtRB1kiz3qEkHGnP0dOQHZ65AtzD7Es9hdu911KVP8UUcXGIQquFtNDQzcAqTq4UGk9U1zlARSDBCRVhiyNKC5wVVOBqZMzj0zma6GR1NgKQVDBP30BiRG659j1l87ah+uV7KpIkwdGLewR+/1ltSyV3LndYbsWLiao8SXCmQxu6OX7gHzA+xqJHEhyA/rY6zIoPr8EyXp8kjiitRGt7rlHaQwdvign8Pgq92iiLrHLpoJoOW8V8PKqRFMVNf6es4kSSJDh68Pvhha9A+1ZIyUb93HPs6tWK9UJDNsVRHTJVPHiQXV89yDslPIE6ktGMCjlLaZqUQCdVldJBfeeAvsFEodGeRix4cKkmSiulcH06ki0WOgxazWlXo4wBiST5qaeHf/8QPvgrGJLgiqfpTirB6fZhUKA8J1Xv6GLGIVPFM8vAaAGfCwaj8zDHSPH7VZIHtQ4qRbanpi+zDLeSjFnx0d2yT+9ook5X4CyXVsVGdoacqzRdvRatVTw4w0tEhiQ4kbbtGXjzl9rHn3gAKs8MdQKV5aRqxbJiWg5ZwTEYx0/rTfBtqraBUUr92lZCqk3eaU+bwcBgoDvIZZcE52BDrdrBkd0WGbI5E6MZlQD4eg7oG0iCkd+mkdT4Nrz4De3jD98CSz8LHDRkU0zbxBWc0NDNYIKT4J1UdV3DVAeGbBrypRh0Jrw52opXUl9ifw9Nxd+t/Zk4M6p0jiTGBLbPk6VVPKIkwYmU3gPw3FXg98CiS+C874U+JQnOsanKS0NRDhq6KZ1UANR2DVFt0BIc6aCameQi7cygLGc9fr8MSJwoOTiIVAa3zkhKkbaKmjOW2FvnkSYJTiSM9sMzn9H+W3wKXPrwpKLPYA1JtSQ4M5KcZKQ4U6sDCHVSBX/wJvhpxk3tXdiUfu1/ZMjmjFhLte6gatpoGxjVOZrokj2mdQGlFS/UOZLYkl8ZmCrus+P3enSOJnFIghNuPg/84WptRcFaGhigObmQuKFHqyGRFvGZqykIblMdPHQzsfe6xzq1DiqXJQdSsnWOJrYYC7UVnBqlnbquIZ2jiR6qa5h8fw8AeTJkc0ZsJVWMqmaSFB9drYn95iuSJMEJJ1WFl2+GhjfAnA6fexYyCidd4vX5ae4bAaAqX1ZwZiq46nVIq7ijFdyJeY6JqqoY+7QtOl+2bCXMWE4NPgxkKKN0tDToHU3U6G/RCox71QzKSkp0jia2mEwm2o3a8OS+JmkVjxRJcMLpPw/A1qdAMcBlj4Ft8SGXtA2M4vGpWEwGiqwxOktLR+MrOIFkJjUHUnK0jxN0FafT4aIocBibpVAKjGfMZGYwWTsYcaRdhm4G9QZ+MbcZS7CYjDpHE3v6k7XOM2eHdOdFiiQ44bLnJXjtDu3jC34E81dPeVn9hAJjg0zmnbGag1dwYMI2VWIWGk8sMDbmS4HxsXBlaStfSo8M3QwaC7TND6RU6BxJbBqzap1nSoK+8dKDJDjh0L4N/nI9oMKpX4IP3XjYSxu6pYPqeARXcFr6R3F7/dqdwW2qRE1wOoepVrQp4tJBdWxMhVrXS8awtPUGKYGjF9xZ1TpHEpuM+drPpZShRn0DSSCS4Mw2Rzv8/krwjED1eXDhz0A5/MqMtIgfn4KMqYZuJnYn1cQp4tLOe2ysZVoRbam3ZfwIggSXPtwIgEnOVTom6cVa0pzrklbxSJEEZza5nVpyM9QBefPh8ifAmHTEh0iCc3wmDt2s6woO3UzsLao+ezPpyhh+xQjZciDbsbDYtLbeOYb2ydufiUpVKXBrv5itZYt0DiY25VdpSbNN7cYzlpgNEJEmCc5s+uf3oWM7pObC556DlKyjPiSY4FRLB9Uxqwn82dX3HNRJ1VundbIlEFVV8QXqRjwZZWAy6xxRjAokyQXKAE1t7ToHoz/PQBupjOFVDdgq5QycY1GQX8ygqv2s6mySmVSRIAnObDrnNqg6B658BnKO/s55zOMLHSQmZ+Acu+AKzoHgCk5Otda55nKAs1vHyCKv1+mmwN0KgEkKjI9dshVHUj4AQy3SSdXdqA3ZbKMAW7ZV52hik8FooMOktdf3N8v3VCRIgjOb0nLh6r9C+YemdXljr/YLOTMliezUI29licMLzaQKruCYLJAVGAaYYHU4EwuMjVIrcVycVu0EaF+3vNseDJyB02kuk27P4zCYqv1cCh7EKcJLEpzZdoSC4oMFO6iq89NQZvA4MVloqnjX8IShm8FtqsRKcOq6JhYYy4iG46HkaQli6qC09Xq7tBbxofRKfQOJcZ5AB5qhLzHrAyNNEhwd1UuB8awIDt10jHnpTfChm7Vd0iI+W9JLA/ODXE2MeXw6R6Mvc2AKtl9Oxj4upjztzy99uFnnSBKDJDg6ChUYS4JzXJKTjJRkaUM3QycaB1cvehIrwWno7KdMCdQd5UqCczzSSrQEp0ZpH/++SlBZI00AWAJTscWxsZZqBdr5bmkVjwRJcHQ03iIuBcbHK1RofMjQzcTaohrtOoBJ8eNLSoMMm97hxDQlXxu6WaZ0UW/v1TkaHXld5Ps6AcgtlyGbx8NWfSIAOQwyNtSvczTxTxIcHckZOLOnZkIdDjC+etHfqE10TwADI26yA++0yZ0zo3owMYX0AkYM6RgVlb7mPXpHoxtnx34MqDjUFMrKK/UOJ6ZlZ2XTTRYA9gYZuhlukuDoZGDEHTohtTIvVedoYt/cggwA9nUOaXdkFEFSKvi90N+kY2SRU9c1TLUSmEEl9TfHT1FwpGtFoZ7OxE1wgi3iLUoJ1hQ5V+l4KIpCZ5I2yHWwVVrFw00SHJ0EC4yLMpNJNZt0jib2LSrWzub4oN2hdVIZDON1OAlSaFzbNUxVIMGREQ2zwx9YCTT3J8b30FSc7VqbfF9ymc6RxIehVG1YqbszsbbP9SAJjk5kyObsml+YgUHRDrrrHnJpdyZYq3hd13Boirh0UM2OlGKtKDRnpAGfP7FOxQ4JnCU1apUhm7PBm6298TINyCDXcJMERydSfzO7UszGUKHx7g6HdmewDidBDvurnbBFJSs4s8NaphWFVtNGW/+oztHoI2WoAQCDnIw9KyyF2p9jhjMxts71JAmOTiTBmX2Lisa3qYAJnVSJcVBbp72DPCWY3Mkhf7PBWKC1RVcrHdR1DugbjB5UlXyXdmZLeonMoJoNWYFWcZu3LeFm5UWaJDg6qZchm7MuVIfTcdAv+QTYohoa85Ay1AiAP90Glgx9A4oXWRV4lCQsioeu5vj/PjqYf7iHDFXrTCyolBbx2VBUtRC/qpDOCEN9Msg1nCTB0YHfr9IoZ+DMuuAKzp72g7aohjthzKFTVJFxoNsZOsHYIPU3s8dgZCClEoDRjsTrpOpr0VqZ29Q8ygpzdY4mPmSkp9OhaINcOxukkyqcJMHRQefQGKMeHyaDQml2it7hxI2FgQSnodeJ0+WFZCukF2qfjPNOqtrOIaoMwRlUUn8zm9yBolBjb+INSAxOve4wlZJklF8Xs6XbrLWKD7UlXtIcSWH9ju3r6+Oqq67CarWSlZXFddddx/Dw8BGv//rXv878+fNJSUmhvLycb3zjGwwODk66TlGUQ27PPvtsOL+UWRXsoCrPSZUfGrMoP8NCQYYFVYW99sB5OKFOqvhOcOq6ZQZVuCQVaicaW4cTr+vFbdeGbA4GWpvF7HAGhpZ6uxNv2zOSwvrb9aqrrmL37t289tprvPTSS7zxxhvccMMNh72+vb2d9vZ2fvGLX7Br1y6eeOIJ1q1bx3XXXXfItb/97W/p6OgI3S699NIwfiWzS4Zshs+hdTgJkuB0DlOtyApOOGSVa51UZf5WeoddOkcTWcbA+T/B1mYxO/w52r9R80CDzpHEt7CdMLdnzx7WrVvHu+++y6mnngrAAw88wEUXXcQvfvELiouLD3nMiSeeyJ///OfQ/9fU1PCjH/2Iz3/+83i9Xkym8XCzsrKw2WJz1o50UIXPoiIrG/Z1j3dSBX/Zx3mreF2ng0pJcMLCbNO6XuYobezrGiY33aJzRJFjDbQyJxXKkM3ZlGKbC3WQOSpTxcMpbCs4GzduJCsrK5TcAKxcuRKDwcCmTZum/TyDg4NYrdZJyQ3A1772NfLy8jj99NN5/PHHtdNrY0QowZEOqll3yApOAgzdHHX78A20kKK4UQ1JkCXbCbMqdw5+DGQqI7S2JtDZJa5hCr1tAGRWLNE5mPiSW6FNqi/ytaP6fTpHE7/CtoJjt9spKCiY/GImEzk5Odjt9mk9R09PD3ffffch21p33XUXH/nIR0hNTeXVV1/lq1/9KsPDw3zjG9+Y8nlcLhcu1/jSssOhb0eNrOCET7CTam+HA6/Pjyl3wlk4qhqXAygPdA+Pr97kVIFRRn/MqqRkBixF5LjaGG79ADhF74giYrjpfdLx06lmUVMtW1Szqah8Hm7ViEXx0N/RQHaJrLqGw4xXcG677bYpi3wn3vbu3XvcgTkcDi6++GIWLVrE97///Umfu/322znzzDM5+eST+e53v8utt97Kz3/+88M+1z333ENmZmboVlam30wVj89Pc98IANXSIj7rKnLTSDUbcXn9NPY6IbsCDCbwjIAjPs+c0IZsal+bkisFxuEwmqn9AlK79+kcSeR07X8HgDrjHLJSZcjmbEq2mGkzFAHQ3SRTxcNlxgnOLbfcwp49e454q66uxmaz0dXVNemxXq+Xvr6+o9bODA0NsXr1ajIyMnj++edJSko64vXLly+ntbV10irNRGvXrmVwcDB0a2lpmdkXPYta+kbw+VVSkowUWhNnLz9SjAaFBTbtkLvd7Q4wJkF2pfbJOC00njhFnDx5JxgOhvx5AKQ6EuNUbABPy/sA9GfJAX/h0GfR3mgPtSfe8QORMuO17Pz8fPLz84963YoVKxgYGGDLli0sW7YMgH/961/4/X6WL19+2Mc5HA5WrVqFxWLhxRdfJDk5+aivtW3bNrKzs7FYpk4YLBbLYT8XaRO3p5Q43C6JBouKrWxtHuCDDgeXLC3RDvzrrdPqcKrP0Tu8WVfbNcTpMoMqrDLKToDdUORpYtTtI8Vs1DuksLP27wJAKV6qbyBxajSjEsY2osZ5A4SewlZkvHDhQlavXs3111/P5s2befvtt1mzZg1XXnllqIOqra2NBQsWsHnzZkBLbi644AKcTiePPfYYDocDu92O3W7H59MKsf72t7/x6KOPsmvXLurq6njooYf48Y9/zNe//vVwfSmzSgqMw29RUSYwYSZVcGRDT3yu4NROnCIuW1RhkV6irWLUKO3U9xz+LK+44XZS4NZWunPnHf4NqTgOgdXWZIe0iodLWKsRn376adasWcNHP/pRDAYDl112Gffff3/o8x6Ph3379jEyotWkbN26NdRhNWfO5HeiDQ0NVFZWkpSUxIMPPsi3vvUtVFVlzpw53HvvvVx//fXh/FJmTWgGlRQYh02ok6rdgaqqKKFOqvhLcFxeH/beAYqTerU75JC/8MjTtqiKlD62ttk5oThT54DCa2KB8fwa+Z4KhzTbfNgD2WP6lUzEu7AmODk5OTzzzDOH/XxlZeWk9u5zzz33qO3eq1evZvXq1bMWY6QFTzGWDqrwmV+YgUGBXqeb7iEXBaHD/uJvKbixZ4QytQODoqImZ6KkyrygsEjJwmHKwertY6DlAzgtvs+F6dr3DuloBcZnpkmBcTjkBVrFC32d+D0uDEnRUUYRT2ROQIRJi3j4pZiNVOdrHWq7Oxzj2zYDzeCNr5NoJxYYK7lz47INPloMp2tbnd7O4+8SjXae1kCBceYinSOJX0WllThVCybFT3eLFBqHgyQ4EeR0ebE7xgBJcMIteB7OB+0OSC8AixVUP/TF1353bdfQhA4q2UoIJzXw55s8EH9bnQez9u0EQCk+WedI4pfJZKTdWAJAX7NMFQ8HSXAiqLFXW73JSTPLuRJhNulEY0UZLzSOs22qyQXGchhbOKUUa6sZuaON+Pyxc3L6jE0sMJ57us7BxLf+ZK1VfKRDVnDCQRKcCJLtqcgJruDsCXVSxWehsTZkUzqoIiEzMHSzijZa+0d0jiZ8nM3vYwwWGM+dp3c4cc2VWaV90BdfP5eihSQ4ESQFxpGzMJDgNPQ6cbq8E4Zuxs8PEq/PT33PUOgUYzkDJ7yMBVphcYXSyYGOPp2jCZ/OvdoJxrXGOWRLgXFYGQLbnqlDjfoGEqckwYkgWcGJnPwMCwUZFlQV9tqHxk/4jaMtqqa+ETJ8DjKVEVQU2aIKt4wiRg2pmBQ/PS3xW2jsDRQYD0iBcdhlFGtJc65LWsXDQRKcCJIzcCJrUh1OHG5RTZpBlVkGSSk6RxTnFIWBVG1LYaw9fotC0/uCJxhLgXG45VdpB0gWqL14R4d0jib+SIITIaqqUt+tnYAqpxhHxqROquDqxkgvjMTH9kJd1zBVhsAUcVm9iQhvtrYSaIrXmgm3k0J3MwA5UmAcdoUFRfSr2uy8zqY9OkcTfyTBiZD+EQ+OMS8AlbmS4ERCcAVnT4cDzGlg1Voy6Y2PgYm1nUPUSIt4RJmLFgKQ6aw/6qGkscjZvA0jfrqkwDgiDAaFDpP2c6m/WRKc2SYJToQ0BObXlGSlkJwU/4P6okFwBWev3aG19cbZica1E7aopIMqMrIDnVQV/lZ6nW6do5l9XaEC4xpypMA4Ihyp5QCMdUqr+GyTBCdC6qWDKuIqctNINRsZ8/i1Au9QJ1XsJzg+v6ptUSmyRRVJZpu2glOjtFPX6dA5mtnnad0KyAnGkeTOqgbA0BcfK8vRRBKcCJEOqsgzGhTm27T97Q86HOPbOHFQaNzWP4rX66EimODIFlVkZFfiIYkUxY29Jfa/jw4WLDBGCowjxpSv/dtNdzbpHEn8kQQnQiTB0cfkQuPgFlXs/2Kq6x6iVOnGrPjAlAzWUr1DSgxGU+j02eHWOOukmlhgPEcKjCMls2QBQOj0aDF7JMGJkFCCIx1UETW5VTyY4BwAv0/HqI5fbecwVcEC45waMMg/5UhxZWnbgUpPfNVMSIGxPmxV2rZnFkOMOXp0jia+yE/FCPD71VCCI2fgRNakFZyscjCaweeCwVadIzs+tV3DEzqo5ATjSAqeaJw+FF81E137NgFagXFuukXnaBJHTnYOneQA0NW4W+do4oskOBHQ4RjD5fWTZFQoyZLD2CJpgc2KQYGeYRddTg/kaAV9sd5JpXVQyQwqPVjLtE6qIk8zI26vztHMnmCBcZ9VCowjSVEUOpO0LeaBFmkVn02S4ERAcAZVeU4qJqP8kUdSitkYqnuaXIcTu+++VVWlrnNofItKZlBFVHqplgDMUdpC3ZHxYPwE46X6BpKAhtMqAHB3xX59YDSR37YREDwDpyovXedIEtOi4kzgoE6qGG4V7xgcw+n2UW2QQ/50kTsXPwo5yjAtrXFSGOoeodCldfFkywnGEecNtIonDcTuG69oJAlOBIRmUEmBsS6m7qSK3QSnrmuYVMawKf3aHXIGTmSZUxlIsgEw2LJL52Bmx0iLVmDcrWYyf44UGEeauVD7M8+QVvFZJQlOBEiLuL6mHroZu++UarsmdFCl5kFKtr4BJSCnVRu66evap3MksyN4gvF+4xzyMpJ1jibxZJdpnVQ2bxvE4QgQvUiCEwGS4OgruILT0ONkxFqp3TnYAu4R/YI6DnVdMoNKd3laJ1XKQHzUTLilwFhXRVUL8KkKqYwx3BvbHZ7RRBKcMHN7/bT0ab9IpUVcH/kZFvIzLKgq7HWYx1c8YvRo9Eln4Mj2lC7SSrREIG+sCa/Pr3M0x2/8BOOlusaRqKxpabQrhQB0NcTZAZI6kgQnzJr7RvCrkGY2kp8hZ0voZXIdTuyObFBVVWsRN0iLuJ6yAkM3q5U2WvpHdY7mOE0oMJYTjPXTbdZaxR1t0io+WyTBCbOJJxgriqJzNIlryhONe2IvwekZdjM46hmfIi5bVLowFGjH65cqPTS0d+kczfEZadkeKjCeJwXGuhnJ0FrFvd2x93MpWkmCE2bSIh4dJq3g5MXuTKrariFApcYQnCIuZ+DoIjWHIWMWAP3NsX36bNe+QIGxoYZ8qxQY68Wfo/1btgzW6xxJ/JAEJ8ykwDg6BFdw9tod+HICdSsx2Cpe1zVMAQOkMgaKEbKr9A4pYTnStD97V0dsbym4WwIFxplSYKynFJu2epY12qxzJPFDEpwwC550KgXG+qrMTSMlyciYx0+bITB5u6cu5loyazuHqTEEtqeyK8Bk1jegBObN0bYHk/pjL1GeKL1vp/ZB0VJd40h0OeUnAFDo60D1xc8IED1JghNmsoITHYwGhQVFGQDsGM0FFHANgjO2pvfWdg1Rpcj2VDRILtbOLskeaUCNsUQ5RE4wjholFXNwqUmY8TJob9A7nLggCU4YDbu8dA25AKiUBEd3wTqcXZ0uyCrT7oyxbaq6ruHxAmPpoNJVdqCTqsLfRs+wW+dojs2oFBhHjWRzEm0G7YTs7qb4OCFbb5LghFFjYPUmL91MZkqSztGIKU80jqGZVP1ONz3D7vEp4nmygqMns01bwalQ7Byw9+sczbHp2j9eYFxgTdE5GtFrKQdguC0+TsjWmyQ4YVQv21NRZXInVeydhVPXrXXkzTV1anfIFpW+rCWMKcmYFR9dTXv1juaYuJqlwDiajFq1VnF/DI+SiSaS4IRRQ7ckONFkgc2KQYGeYRdDadoPklhKcGo7h0nCS7EaTHBki0pXBgP9Kdr30Uh7bJ4+GzzBWJUC46igBP5NJzukBmc2hDXB6evr46qrrsJqtZKVlcV1113H8PDwER9z7rnnoijKpNtXvvKVSdc0Nzdz8cUXk5qaSkFBAd/5znfweqOv6lzOwIkuKWZjKNmsV4u0O2MpwekaolzpxIgfzOmQYdM7pITnytJW0Qy9+3WO5Bh4Ril0NQJygnG0SCvSZpzljEmr+GwIa4Jz1VVXsXv3bl577TVeeukl3njjDW644YajPu7666+no6MjdPvZz34W+pzP5+Piiy/G7Xbzn//8hyeffJInnniCO+64I5xfyjGRDqros6g4E4Dto3naHX0NECMtmVqB8YQZVHIytu6SbNqJxhlDsXc421jrtkCBsVUKjKNEbqXWKl7g68LvHtM5mtgXtgRnz549rFu3jkcffZTly5dz1lln8cADD/Dss8/S3t5+xMempqZis9lCN6vVGvrcq6++ygcffMDvfvc7li5dyoUXXsjdd9/Ngw8+iNsdPZ0MqqqGanCq8yXBiRbBOpx3e1PAlAJ+Dww06RzV9NR2TkxwZHsqGgRnUhV7W3C6YiNRDurcuwkIFBhnSoFxNCguLmNYTcGoqPS2SqHx8QpbgrNx40aysrI49dRTQ/etXLkSg8HApk2bjvjYp59+mry8PE488UTWrl3LyMjIpOddvHgxhYWFoftWrVqFw+Fg9+6pj0x3uVw4HI5Jt3DrdboZGvOiKFCekxr21xPTE+yk2m0fHi/SjYFtqqExD3bH2IQp4lJgHA3SSrR33DVKO/VdR95+jzbuli0A9FpP0DkSEZRkMtJmLAagpzk267oABofHaOzW/99D2BIcu91OQUHBpPtMJhM5OTnY7fbDPu5zn/scv/vd7/j3v//N2rVr+b//+z8+//nPT3reickNEPr/wz3vPffcQ2ZmZuhWVlZ2rF/WtAW3p0qyUkhOMob99cT0BFdwGnqceLOrtTtjoFW8LvDLc0FSoMBYhmxGh5xqvBhJV8Zoa4mtzpe0Xikwjkb9KVqr+GhH7K7g7Pjn/2H59WJeeuCbusYx4wTntttuO6QI+ODb3r3H3jJ5ww03sGrVKhYvXsxVV13FU089xfPPP8+BA8f+w2Pt2rUMDg6Gbi0tLcf8XNMlHVTRKT/DQn6GBVWF7sCZE7GwglMbSHCqQof8yQpOVDAm0WfRRn8MtcTQ0E0pMI5abqs240yJ4VZxpe6fFCl9lCR7dI3DNNMH3HLLLVxzzTVHvKa6uhqbzUZXV9ek+71eL319fdhs0+/+WL58OQB1dXXU1NRgs9nYvHnzpGs6O7V3tYd7XovFgsVimfZrzoZQ/Y0kOFFnUZGV14e6qVeLKIKYSHDquoaxMkymf1C7I7dG34BEyIi1GrqbULtj5x33WOs2koMFxnOlwDiaGPLnQgekDjfqHcoxcXt8zBvaBApknnSRrrHMOMHJz88nPz//qNetWLGCgYEBtmzZwrJlywD417/+hd/vDyUt07Ft2zYAioqKQs/7ox/9iK6urtAW2GuvvYbVamXRoug5rGq8RVwSnGizqNjK6/u72T6ax5kQE1tUtZ1DVAdnUGUUgSVD34BEiCF/PnT/m5TB6E+Ug7r2baIcrcD4TCkwjioZxQtgB+S6wr/TEA4fbHubpUo/IyRTefJKXWMJWw3OwoULWb16Nddffz2bN2/m7bffZs2aNVx55ZUUF2tFVG1tbSxYsCC0InPgwAHuvvtutmzZQmNjIy+++CJXX301Z599NieddBIAF1xwAYsWLeILX/gC27dv55VXXuF73/seX/va1yK+SnMkoRbxfDkDJ9oE63De7svS7hi2g2tIv4Cmoa574gwq2Z6KJuml2hurAlcTXp9f52imJ3SCsTV63hQKTUGl9neSp/bjHRnUOZqZG9j+dwDq00/BYE7WNZawnoPz9NNPs2DBAj760Y9y0UUXcdZZZ/G///u/oc97PB727dsX6pIym83885//5IILLmDBggXccsstXHbZZfztb38LPcZoNPLSSy9hNBpZsWIFn//857n66qu56667wvmlzIjPr9LYq31NskUVfYKdVFu6/KhpgdXIKN6mGnF7ae0fpcogU8SjUVb5YgCqlTaa+0aOcnV0CBYY+6XAOOoUFhTSq2o/o7qa9+gczczldrwBgK9G39UbOIYtqpnIycnhmWeeOeznKysrUVU19P9lZWW8/vrrR33eiooK/v73v89KjOHQPjCK2+vHbDRQnCXLv9GmMjeNlCQjox4fY9ZqUpzd0FMHxSfrHdqU6rudqCosMAUSHOmgiiqGfK2GJV9xsKu1jer8+TpHdBSeUQpd2iiAbCkwjjoGg4LdVEKuz0F/8x6KF3xI75Cmzd5pZ6F3DyhQefon9A5HZlGFQ3B7qiI3FaNBTpuNNkaDwoIirYalyxw4MiCKV3Bqu7Tts3nBBEcO+YsulnT6TVo9YH9z9HdSjbVun3CCcZQnYwlqIFWbcebqjK0RIHXvvIRJ8dNqLCWzRP+fU5LghIGMaIh+CwN1OPVqoPOuN3oLjWs7h1HwU+wL1uBIB1W0GUrXWnu9ndG/pdC1b/wE48JMfWskxNQ8WdoZXYa+2GoVV+r+CUB34Yd1jkQjCU4YjBcYS4ITrYKFxttHor8Gp7ZrmGJ6SVLdYEiCrAq9QxIH8eVq21Tm/uj9PgpyNQdPMF6EIvPMolJSgbb6ke6MjTEyAB6vjzmOdwCwLta3PTxIEpwwkDNwol+w0PitgSztjt4DMKEeLJoc6BoeLzDOqQJjWEvnxDFIKdY6X3JGGybVFUaj0AnGtiU6RyIOJ7NUG+Ja6G6J2p9LB9u7bSOFSj+jWKhadr7e4QCS4ITF+Bk40iIerRbYMlAU2D6cjaoYwT0MQx16h3UIl9dHY69zQou4/vva4lA5ldrQzUp/K91DLp2jOYIJBcZZUmActWyBVvEMnIwNHH60UTTp3f4yAPVpJ2MwR0dzjSQ4s8zl9dHaPwpIDU40SzWbqMpLw4OJ0fToLTRu6HHiVyfOoJIW8WhkLlwIQKnSQ31Hj87RHJ6rbQdG/PSoVubNlQLjaJWblcl+tK3o1vf+dpSro0OwPdxbrX97eJAkOLOsuXcEVYUMi4m8dLPe4YgjCNbhdCVps4Si8UTj2k5tNXChOTD2RM7AiU5peQwbMjAoKj2N0dtJ1RkoMN5nqMYmJxhHLUVRaMj/CAC+nS/oG8w0dHV3sdCjTT8vX65/e3iQJDizrH5CgbEU8EW3YB1OvaqdrB2NKzjBIZsVqmxRRTVFYSC1EoCxjujtpAoVGGdIgXG0yzr10wBUOTbhH43uE41rA+3hbcYSskujZ2VQEpxZJi3isSO4grNtJE+7IwoTnLquISy4yfYEt6gkwYlW7mzt78YQxUcOpPXsBECVE4yj3tJTPkS9WoIZL40b/6J3OEdW+xoAnQXR0R4eJAnOLGvolgQnVgRXcDYP5Wh3ROEWVV3XMJWKHQUVkjMhNVfvkMRhJNm0OpxMZ73OkRyGFBjHFEuSibq8jwLg2vG8ztEcnndCe3jG4gt1jmYySXBmmazgxI6CjGTy0i0c8GuT6hloAq9b36Am8Pj8NPQ4qVYC3V25c0G2FaJWTrnWSVXibWHY5dU5mkNNLDCeKycYx4SMUz4FQPXARvxj0TkQeO+Odyikj1HMVJ+6Su9wJpEEZ5aNn4EjLeKxYFGxlW6y8BhTQfVDf4PeIYU09Y7g8akygypGpAWmilcpHdR3Rl/NRPAE431KNUUyIy8mnHzah2lWC7HgpumdF/QOZ0p924Lt4adgjJL28CBJcGaRY8xDz7B2BkZlXqrO0Yjp0OpwlPGZVFG0TVUXmEG1OCXQdiwjGqJbZjluzFgULx2Ne/WO5hBygnHsSTab2JerdVONRuk2VXa7NiDbU/URnSM5lCQ4s6gxsHqTn2EhIzlJ52jEdATrcOqC21RRVGgcbBGvMUzYohLRy2CgN7kcAGfbBzoHc6jUwAnGfjnBOKakLdW2qSr73kZ1O3WOZrLunm4WeLSuwbLll+gczaEkwZlFDTKiIeYEO6l2jAY7qaJoBad7GFCxeVq0O2SLKuqNZmrnFKnd+3SO5CCeMQrGpMA4Fp28/CO0qfmkMkbT5ug69K/2nZdIUny0GYrJLVugdziHkARnFo24fWSlJlEtQzZjRlVeGslJBvZ7A1PFe6JrBSeHISzeIUCBnGq9QxJHYSjQinfThqKrk8rVtgMTPnrVDObOjb5fROLwUiwm9mafC4Dz/ShrFw+0h9ujrD08SBKcWfTZ08vZdscF/OATJ+odipgmo0Fhgc1KvRpdW1Q+v8qB7uHxGVSZZZAUXQV84lAZZScAYHM14fH5dY5mXNd+rcB4r1JDsRQYxxzLkk8CUNn7BqpnTOdoND6fn5rBjQBknBhd7eFBkuCEgdkkf6yxZFGxlYZggjPSA6P9+gYEtPaP4PL6mWsKHPAnBcYxITvQKl6ttNPcGz31Eq4mrcC4RwqMY9LJK87HruaQxijN772sdzgA7N2xiUL6GCOJ6lMv0DucKclvYpHwFhVZGSGZPmOwDueAvgExXmB8Smqgg0rqb2KCIW8OPgxYlRGam6PnyIHU3sAJxlJgHJPSks18kHUOAENb/6xzNJrebS8BcCD1FEzJ0VmWIQmOSHjBTqoD/mAdjv6FxsEZVPOTAmfgSAdVbDBZ6EvSVgMdLbt0DiZgUoHxaToHI46VebG2TVXRvQHV69I5mvH2cFcUtocHSYIjEt4CWwaKAvs8hdodUdBJVRdIcEp9wSGbskUVK4YytGJwX2d0dFJNLDCeM0cKjGPVkjNW0a1mkoGT1vdf0TWWvt4eFri1oxAqTo++9vAgSXBEwks1m6jKS4uqqeJ1XUMY8ZE11qrdIVtUsSNP66SyDOj/fQTQHSowrqYkWw4gjVUZqcnssmrbVAPv/UnXWPaH2sOLyK1YqGssRyIJjhBodTj1anS0iquqSm3XMKVKNwbVA6ZksJbqGpOYvtQSbWRD7mgjqqrqHA2MBU4w7smQAuNYl7RYWy0p7/oX+PSbd+bfH93t4UGS4AiBVocTWsHpOwB+/Vp82wfHGHH7mGMI1N/k1IBB/qnGipxKrZOqkja6hvSvlUjtCZxgXCQFxrHupLMupk9NJ1MdonXba7rE4PP5qQ60h6edsFqXGKZLfmoKgbaC06bm4cEE3jFwtOoWS22nNoPq1PRe7Y68ObrFImbOXKjVudiUfhpbO/QNxjNGwZh26GBWjZxgHOusqSnszNBWTfre1WebqnbXu9joZUxNouY0SXCEiHqLiq34MNLoDxQa69hJFSwwPtHSpd0hHVSxJTmTAWMuAL1NO3UNxd0uBcbxRll0KQClnf8Evy/ir9/9fqA9PO1kkqK0PTxIEhwhgIKMZPLSLRNONNbvLJxgglOhBIdsygpOrBlIqwLA1bFH1zi69o0XGJfmSIFxPDjpwx9jUE0jRx2gbee/I/76mW0bAHBVRm97eJAkOEIETDrRWMdW8eAZOPmuZu0O6aCKOd5s7e/M1KfvkQNSYBx/sjLS2ZF+BgC9m/8Q0dfu7+9jgXs3AKWnfyKir30sJMERImBRkZUDwQRHpy0qVVWp7RwijVFSxoJbVHIGTqwxF2mts1lOfU8zlgLj+KQu1Lqpitv/GdGGiP0b/4ZZ8dFuKKKg8oSIve6xkgRHiIBFxVbq/fpuUXUPuXCMeakOdlCl5kFKti6xiGMX7KQq8bUyNObRJ4gJBcaZ1XKCcTw58cOXMqSmkKf20vHBmxF73WB7eHv+mRF7zeMhCY4QAYuKxreo1MEW8IxGPIbg9tTpGX3aHbI9FZPSS7R3txVKJw32Pl1icHfsxISPPjWduXOj9zA2MXM5mRnsSP0QAJ3vRGabyu/zUzUQbA+PzunhBwtrgtPX18dVV12F1WolKyuL6667juHh4cNe39jYiKIoU97++Mc/hq6b6vPPPvtsOL8UkQCq8tIYScpkQE1DQYW++ojHECwwXhIcsikFxrEpvZARJRWjotLZ8IEuIXSHCoxrpMA4DnkXaDUwRe2vQgQOlKz94D1s9OCKgfbwoLAmOFdddRW7d+/mtdde46WXXuKNN97ghhtuOOz1ZWVldHR0TLr94Ac/ID09nQsvnJwx/va3v5103aWXXhrOL0UkAKNBYYEtc7zQWIc6nNou7QycOQbpoIppikJvSiUAI+36JDijTVsB6JYC47h0wtmfwqlaKPR3Yd+7Meyv171Vaw+vTV2KOSU97K83G8KW4OzZs4d169bx6KOPsnz5cs466yweeOABnn32Wdrb26d8jNFoxGazTbo9//zzfOYznyE9ffIfaFZW1qTrkpOTw/WliASinWisXydVbae2glPklRlUsW4sK5Cc9ugzdDO1ZwcAPpsUGMejvOwsdqQsB8C+8bmwv541htrDg8KW4GzcuJGsrCxOPfXU0H0rV67EYDCwadOmaT3Hli1b2LZtG9ddd90hn/va175GXl4ep59+Oo8//vgRZ764XC4cDsekmxBTWVhk5YCOhcbaFpWKdaRJu0NWcGKWqUA7WC9jKPJbnZNPMJYC43jlmf8xAApbXwnrNtVAfx8LXFpHXiy0hweFLcGx2+0UFBRMus9kMpGTk4Pdbp/Wczz22GMsXLiQM844Y9L9d911F3/4wx947bXXuOyyy/jqV7/KAw88cNjnueeee8jMzAzdysrKZv4FiYQwsdA40ltUvcMuep1uChjA6HGCYoTsqojGIGZPZrnWSWVzN+PxRXa2madjV6jAeM4cKTCOVws//GnG1CSK/B101b4XttfZ/87LWnu4YqMwBtrDg2ac4Nx2222HLQQO3vbu3XvcgY2OjvLMM89MuXpz++23c+aZZ3LyySfz3e9+l1tvvZWf//znh32utWvXMjg4GLq1tLQcd3wiPi2wZdCAluD4e2ojUrwXFCwwXm4NzKDKrgCTOWKvL2ZXdoWW4FQr7TT1HL65Ihy69r0DaAXGZblSYByv8vNy2Z6srdC1hXGbyrf/VSDQHh5D9VymmT7glltu4ZprrjniNdXV1dhsNrq6uibd7/V66evrw2azHfV1/vSnPzEyMsLVV1991GuXL1/O3XffjcvlwmKxHPJ5i8Uy5f1CHCzNYoLsavzDCgbXIIz0QlpeRF67rlv7JXhqei/0IdtTMU7JqsCDiWTFQ1vjPuYURm6raLQ5WGC8QAqM49zY3I/Brv9Q0PwPUH8+6wmI3+enol8rYk5dFBvt4UEzTnDy8/PJz88/6nUrVqxgYGCALVu2sGzZMgD+9a9/4ff7Wb58+VEf/9hjj/GJT3xiWq+1bds2srOzJYkRs6KmJJ/2fbmU0qNtU0UowQkWGC9I6tTukCGbsc1oottSRrGrgaGW3bA8cglOSo825FMKjOPfgrM/g2vnHZT4Wump305ezdJZff4De7Yyl26tPXx5bLSHB4WtBmfhwoWsXr2a66+/ns2bN/P222+zZs0arrzySoqLiwFoa2tjwYIFbN68edJj6+rqeOONN/jyl798yPP+7W9/49FHH2XXrl3U1dXx0EMP8eMf/5ivf/3r4fpSRIJZVDTxROO6iL1ucIuqzN+m3ZEnKzixbsSqjdnwdB7/tv20eV0UjAZPMD49cq8rdFFYkM9OyykAtLz9+1l//s5Qe/hJWFIyZv35w2nGKzgz8fTTT7NmzRo++tGPYjAYuOyyy7j//vtDn/d4POzbt4+RkZFJj3v88ccpLS3lggsuOOQ5k5KSePDBB/nWt76FqqrMmTOHe++9l+uvv37W4/f5fHg8Oh2zLo6b2WzGYJh5Dh9sFT+bnRFtFQ+egZPjCtSIyRZVzDPbFkL3P/HY9/D6/m7OmXf0Fenj5WnfRRJercBYTjBOCM45F8MHm8lpXgf8dFaf29q6AYDRithpDw8Ka4KTk5PDM888c9jPV1ZWTtne/eMf/5gf//jHUz5m9erVrF4d3mUyVVWx2+0MDAyE9XVEeBkMBqqqqjCbZ1aoe0KRlX8HOql83bUYwxHcQQZHPXQ6XCThxTIUTHBkiyrWlS1aDjsf4BOGt7nhmWco+ep1zCkI7yFpXfvfoQTYo9RwRm5aWF9LRIe5Z1+BZ/ddVHgb6W3aRW6gwP14DQ72M9+1ExQoPS122sODwprgxKpgclNQUEBqaqoU6cUgv99Pe3s7HR0dlJeXz+jvMD/DQq+lHPzg6dofkQQnuD21LGMAxeMDczpkHL0YX0Q3Zd6F+OauJrl2HQ+oP+Gbv83iV1//LFmp4euOG2vaAkBPuhQYJ4piWxFbzUs5xbOF5reeJbfih7PyvLXv/J1TFS/tSiHF1Ytn5TkjSRKcg/h8vlByk5ubq3c44jjk5+fT3t6O1+slKSlp2o9TFIWkwnnQAUmDjeDzgjG8/1QOBFvEM/ugB8itial2THEYRhPGy3+L54mPk9n+Hj8e+T63P5XNvdd/jCRjeEogpcA4MQ3VXAR7t5DV+A9gdhIc9z6tPbwt70yKY/DnkUwTP0iw5iY1Vc6OiHXBrSmfzzfjxxaW1TCmJmFUvTDYPNuhHSJYf3OiOXC0gmxPxQ9zKkmf/yOu7LkUK318o/02fvHCO+F5La+L/ECBsVUKjBPKnA9fgVc1UOWpo6/1+MeDqH4/lX3/ASBlUWx1TwVJgnMYsrQb+47n73BRcRYNamCLqCf8nVS1gRWcquCQTZlBFV9Sc7Bc8wJjKYXMNbRx/vZv8szbs99Z5e3QCoz7pcA44ZSUlLHLrG0jNb357HE/X/3ebRTThVs1Mef02Dr/JkgSHCGmcMKEoZv+nv1hfS2fX2W/XVvBKXRLB1Xcyiwl+dq/MmbK4FTDfvJf+Sr/2T+9sTXTFTzBeI9STUWeFBgnmsFKLRGxNrx83M9l3/I3APanLCE5zXrcz6cHSXCEmEJVXjrNSgkAw23hO8OkY3CUzz3yDu2DY5iNBtKGG7VPSIITnwoWYvnCH3ArZs43bKHjma/S0D17YxxGAwXG3ekLZRU6AVWfdSV+VaHGvY+BjuMb8presgGA0Yrzjj8wnUiCEweONhvs+9//vt4hxhyjQcGVWQ2Auys8Kziv7LZz4X1vsqmhj1SzkfsurcQw0qN9MrcmLK8p9KdUnAGXPYYPA5exnjcf+RaDo7Nz3lZyoMDYKwXGCamsoordSdowzIbj2KYacgyw0LUDgOJTPz4rselBEpw40NHREbr96le/wmq1Trrv29/+duhaVVXxer06Rhs7zIXzALAMHN87oYONeXzc/sIu/t//bWFgxMPikkxe/saHubDIqV2QUQSW2DoxVMyM+cRP4DxfO5DtavcfeP5/78J7vBPHJ5xgLAXGiau/QisITjvw0jE/x/53/oFZ8dKhFFAyJ3aTZUlw4oDNZgvdMjMzURQl9P979+4lIyODf/zjHyxbtgyLxcJbb73FNddcw6WXXjrpeW666SbOPffc0P/7/X7uueceqqqqSElJYcmSJfzpT3+K7Beno9wK7Z1QhqcbXLOzjbC/c4hLfv02//dOEwA3nF3Nn288g6q8NG3uFcj2VIKwnnkDnad8C4Cr+x7gL08/dFzPJwXGAqD8rCsBmOfajaPz2DpA3fteAaA1N7amhx9MzsGZBlVVGfXMvNX4eKUkGWdtH/22227jF7/4BdXV1WRnZ0/rMffccw+/+93vePjhh5k7dy5vvPEGn//858nPz+ecc86Zlbii2ZzyUnpUK3mKQ5tJVbz0mJ9LVVWe3tTM3S99gMvrJy/dzC8/s3Ty0f3BuVeS4CSMwo/fSXN/O+UNz3HJgTtY/w8bH73wsmN6rq59mygG9lDNh+QE44RVWTWXD4wLWOTby4E3f8/Jn/7ujB6v+v2U92rt4ZZFq8IRYsRIgjMNox4fi+54JeKv+8Fdq0g1z85f0V133cX5558/7etdLhc//vGP+ec//8mKFSsAqK6u5q233uI3v/lNQiQ4C2wZfKAWkac4cLTtxXqMCc7AiJvb/ryTdbu1jpmz5+Xzy8uXkJ9hmXxhcO6VtIgnDkWh/AsPceDBTmp6N3D6O19jR0EhJy07a8ZPFSww7spYgMEQu++6xfHrKV8NDXtJqXsZmFmC07h/B1V04lZNzFt+cXgCjBDZokoQp5566oyur6urY2RkhPPPP5/09PTQ7amnnuLAgQNhijK6pFlMdJvLAOhr3n1Mz7GpvpcL73uTdbvtJBkVvnfxQp645rRDkxsYP29HDvlLLAYj1f/v99SlnESGMortb1+gvXHmB7UFC4x9hbFbMyFmR9mZ2jbV3NEdDPW2zeixHVteBGB/ykkx2x4eJCs405CSZOSDuyK/VJeSNHtTkNLSJi9ZGwyGQwadTpycPjys1Zy8/PLLlJSUTLrOYpnil3OccmVVQw94OmfWSeX1+XngX3U88K9a/CpU5aVx/5Uns7g0c+oH+P3QF0gcpYMq4SjmVEq+8gKN959Hpa+Jlqc+yfCaf5GeM815ZF4XBaPa94+1+rQwRipiQdWchew1zGWBv5YDbzzH0k/ePO3HpjdvAGCkPHbbw4MkwZkGRVFmbasoWuTn57Nr165J923bti00s2nRokVYLBaam5sTYjvqcCyF86EHLIPT76Rq7R/hpme38V5TPwCXnVLKXZecQJrlCN9DjlbwjoEhCbIqjjdsEYNSMnNJvfYF7I+eT5m/jQMPX0LKzesxJh99+rjXvpskvAyoadTMXRSBaEW06y69gAXNtZj3/w2YXoIzPOxg/tgOUKBoWey2hwfJFlWC+shHPsJ7773HU089RW1tLXfeeeekhCcjI4Nvf/vbfOtb3+LJJ5/kwIEDbN26lQceeIAnn3xSx8gjK7dC+2WR52qBg1a8pvKPnR1cdN+bvNfUT7rFxH1XLuWXn1ly5OQGxjuocqrDPthTRK+C0mr6L3tWS1Tce2l4+HLwHf2MnO59mwD4gBoq846eEIn4V3zmFQDMG9nGcH/XtB5T+87fsSgeOpR8SufG/lanJDgJatWqVdx+++3ceuutnHbaaQwNDXH11VdPuubuu+/m9ttv55577mHhwoWsXr2al19+maqqKp2ijryquSfiUxVSGWW07/B72aNuH2v/spMbn96KY8zLkrIs/v6ND3PJ0pLDPmaS3uD2lHRQJbqFi09jx9n/y6hqZs7Af2j87XVHTa5HggXG6VJgLDTV806i1lCFSfFT+8Zz03qMa4/WTNOSeyaKIfbTg9j/CsQk11xzDQMDA6H/P/fcc1FVlaysrEOu/cEPfoDdbmdgYIB7772XBx54gA0bNoQ+rygK3/zmN9m7dy9ut5uuri7WrVvH2WefHf4vJErkZ2XQrhQC0HZg55TX7Olw8PFfv8XvNzejKHDjuTX86SsrKM+dwUT6UAeVJDgCzv7ox1i38B68qoHK1r/S8fx/HfH6lG7t1FmvFBiLAEVRsJdotaNJ+1486vWq309Z39sAJC+M7fbwIElwhDgCRVHoTS4HoK9pcieVqqo8+Z9GLnnwbeq6hinIsPC765bz3dULSDLO8J9Wr3RQicku+cx1PFOgHQRYtON/GNjwwNQXel3kBwqMM2ukwFiMK/zQZwCY59zCiKP3iNc21+2kRNXaw+csvygS4YWdJDhCHIU769CZVH1ON9c/9R53vrgbt9fPRxYU8I9vfpgz5+RN/4n9fuirhw9eBHtgdUi2qESAwaBw2Zf/iyeTvwCAdcPtjG079CTxiQXG1VJgLCaYu+gU6pVyzIqP/W/88YjXtr8bmB6evJjU9KwIRBd+Us0oxFFYCueBHZIDnVT/OdDDt57bRqfDhdloYO1FC7jmjMojnzrtdkLnB9C5E+y7oHMXdO4G94QREIoR8ueH+asRsSTNYmLl//sZf7i/m8+o6zC+8BX8GXkYas4NXdO9fxNFaCcYL5cCYzGBoii0F19AddujGPb8FT72lcNem9bybwCcZedGKLrwkwRHiKPIqzwBtkO+q4Wfv7KX/9lwAFWFmvw07v/syZxQPOFsG1WFwVYtgbHvGk9o+uqBKQpFjRYoWACFi2HBRZCaE7GvS8SGkuxUaq5+kH/89nNcaNiE65nPYfnyP6BIq7cZadQKjDvTF0qBsThE/vLPwF8eZf7wu4wO9ZOSceionhGng/mj20EB26mf0CHK8JAER4ijsFWfBEAJXfzvv/ehYuLK08q448JqUgdqYeuuCQnNLhgbmPqJ0guh8ESwnaglNLYTtZobaQsXR7GsKo/nP/YQ77x0FR9iD2NPfJLk/7cecqpIDhUYn6RzlCIazTvxNJqfL6acdra/+WeWXPTlQ67Z/84/WKp4sJNP+bylkQ8yTOQnqxBHYbQWMaqkkMIoa5P/xKoyPyX2Ovh5LahTDGE1mCBvfiCRmZDQpOcfeq0Q0/TJ02u4t/MBMt/9EgtdzbieuBTLl/8x4QTj03WOUEQjxWCgxXY+5R1Pou75K0yR4IwF2sObc8/AFgft4UGS4AhxNIqCL7sG+nbxJV6ElgmfS8mZvCJTeKJWR2NKnHEWInK+efGp3Nr5M77VsoZSRyPeR1ZKgbE4qpzTL4e/Psl8xzuMOR2TZkypqkppr9Yebl4QH+3hQZLgCDEN6efeBBt/DTlVYFs8ntBkFMGRiouFmEVGg8IPvnA+33zgbn4+9B1yhrTDJz+gmg/lS4GxmNqCJWfS9tdCSpROtr/1PEtWfTH0uZa6nZSrdtyqkblx0h4eFD9rUUKE00mXw/97HS5/Aj58C8y7AKzFktyIiEu3mPj+ly7lm4b/YkTVVgq7pMBYHIFiMNBUuBIA/+4XJn0u2B5em3wiadZDC5BjmSQ4YsauueYaLr300tD/n3vuudx0000Rj2PDhg0oijLp5GYhEkFZTiprvnAl1/tu5SXfh2iqulLvkESUyz710wDMc/wH1+j48RSpzVp7+FDpuXqEFVaS4MSRa665BkVRUBQFs9nMnDlzuOuuu/B6vWF93b/85S/cfffd07pWkhIhZsfy6lyuvPxz/Kbgdi44U04wFkc2/5RzsZNHGmPsf1sb3TA2Msy80W0A2OJgevjBJMGJM6tXr6ajo4Pa2lpuueUWvv/97/Pzn//8kOvcbvesvWZOTg4ZGRmz9nxCiOn5+JJi/vb1s1hYZD36xSKhGYwG6vM/CoB75/MA7Nv0D5IVD53kUrFgmZ7hhYUkOHHGYrFgs9moqKjgxhtvZOXKlbz44ouhbaUf/ehHFBcXM3++dmJuS0sLn/nMZ8jKyiInJ4dLLrmExsbG0PP5fD5uvvlmsrKyyM3N5dZbb0U9aLLxwVtULpeL7373u5SVlWGxWJgzZw6PPfYYjY2NnHfeeQBkZ2ejKArXXHMNAH6/n3vuuYeqqipSUlJYsmQJf/rT5GPp//73vzNv3jxSUlI477zzJsUphBDiyDKXXQbAvME3cY+NMvbBOgCacs6Ii+nhB5MuqulQVfCMRP51k1KPu4g1JSWF3l5tyNr69euxWq289tprAHg8HlatWsWKFSt48803MZlM/PCHP2T16tXs2LEDs9nML3/5S5544gkef/xxFi5cyC9/+Uuef/55PvKRjxz2Na+++mo2btzI/fffz5IlS2hoaKCnp4eysjL+/Oc/c9lll7Fv3z6sVispKSkA3HPPPfzud7/j4YcfZu7cubzxxht8/vOfJz8/n3POOYeWlhY+9alP8bWvfY0bbriB9957j1tuueW4/myEECKRLDhtJd3rssmnn50bX6KkR2sPN82Pr/bwoLAlOD/60Y94+eWX2bZtG2azeVo1F6qqcuedd/LII48wMDDAmWeeyUMPPcTcueMTlvv6+vj617/O3/72NwwGA5dddhn33Xcf6elhbJH0jMCPi8P3/IfzX+1gTjumh6qqyvr163nllVf4+te/Tnd3N2lpaTz66KOYzWYAfve73+H3+3n00UdDc5R++9vfkpWVxYYNG7jgggv41a9+xdq1a/nUpz4FwMMPP8wrr7xy2Nfdv38/f/jDH3jttddYuVKr2q+urg59PidHG0VQUFBAVlYWoK34/PjHP+af//wnK1asCD3mrbfe4je/+Q3nnHMODz30EDU1Nfzyl78EYP78+ezcuZOf/vSnx/TnI4QQicZoNFKX9xHye/6MaeN9lKodeFQjcz90sd6hhUXY1qTcbjeXX345N95447Qf87Of/Yz777+fhx9+mE2bNpGWlsaqVasYGxsLXXPVVVexe/duXnvtNV566SXeeOMNbrjhhnB8CTHppZdeIj09neTkZC688EKuuOIKvv/97wOwePHiUHIDsH37durq6sjIyCA9PZ309HRycnIYGxvjwIEDDA4O0tHRwfLly0OPMZlMnHrqqYd9/W3btmE0GjnnnHOmHXNdXR0jIyOcf/75oTjS09N56qmnOHBAO6V1z549k+IAQsmQEEKI6ck4WdumWujeCcB+ywlkZMbnDLywreD84Ac/AOCJJ56Y1vWqqvKrX/2K733ve1xyySUAPPXUUxQWFvLCCy9w5ZVXsmfPHtatW8e7774b+iX7wAMPcNFFF/GLX/yC4uIwrbIkpWqrKZGWlDrjh5x33nk89NBDmM1miouLMZnG/4rT0iavBg0PD7Ns2TKefvrpQ54nP//YxgoEt5xmYnhYa1l8+eWXKSkpmfQ5i0VOBBZCiNmy4PQL6H0tk1wGgfhsDw+KmhqchoYG7HZ7aFsDIDMzk+XLl7Nx40auvPJKNm7cSFZW1qQVhJUrV2IwGNi0aROf/OQnwxOcohzzVlGkpaWlMWfOnGlde8opp/Dcc89RUFCA1Tp1F0ZRURGbNm3i7LPPBsDr9bJlyxZOOeWUKa9fvHgxfr+f119/fdLfZVBwBcnnG5/htGjRIiwWC83NzYdd+Vm4cCEvvvjipPveeeedo3+RQgghQkxJSdTlnEtu318BKDjlYzpHFD5RUzZtt9sBKCwsnHR/YWFh6HN2u52CgoJJnzeZTOTk5ISumYrL5cLhcEy6CW27Ly8vj0suuYQ333yThoYGNmzYwDe+8Q1aW1sB+OY3v8lPfvITXnjhBfbu3ctXv/rVI9ZTVVZW8sUvfpEvfelLvPDCC6Hn/MMf/gBARUUFiqLw0ksv0d3dzfDwMBkZGXz729/mW9/6Fk8++SQHDhxg69atPPDAAzz55JMAfOUrX6G2tpbvfOc77Nu3j2eeeWbaq4NCCCHGpZ1yOQDtSgFVi+L3DKUZJTi33XZb6CC5w9327t0brliP2T333ENmZmboVlZWpndIUSE1NZU33niD8vJyPvWpT7Fw4UKuu+46xsbGQis6t9xyC1/4whf44he/yIoVK8jIyDjqStlDDz3Epz/9ab761a+yYMECrr/+epxOJwAlJSX84Ac/4LbbbqOwsJA1a9YAcPfdd3P77bdzzz33sHDhQlavXs3LL79MVVUVAOXl5fz5z3/mhRdeYMmSJTz88MP8+Mc/DuOfjhBCxKcTz/o4755+HyOX/S4u28ODFPXgQ02OoLu7O9RyfDjV1dWTClmfeOIJbrrppqN2UdXX11NTU8P777/P0qVLQ/efc845LF26lPvuu4/HH3+cW265hf7+/tDnvV4vycnJ/PGPfzzsL16Xy4XL5Qr9v8PhoKysjMHBwUO2ZsbGxmhoaKCqqork5OQjxiyim/xdCiFEfHE4HGRmZk75+/tgM6rByc/PP+bi06OpqqrCZrOxfv36UILjcDjYtGlTqBNrxYoVDAwMsGXLFpYt005d/Ne//oXf7z+kw2Yii8UixapCCCFEAgnb2lRzczPbtm2jubkZn8/Htm3b2LZtW6hjBmDBggU8/7x2ZLSiKNx000388Ic/5MUXX2Tnzp1cffXV/P/t3W1sU2UbB/B/i22HZGzRsZe6FwYRMDgWJNIMNRq2sE0iWzDCCFGICIZsiUSN8wtU4wdUjB8gZPKBbRoMiIlAIgSyzW3qHMywGQFNM0gzJXtTkm1lczLb6/ng0xO69WWn0pdz+v8lTdZzrnNzX7t6h2unpz1Wq1W5saP3rYudO3eiq6sLHR0dqKmpQVVVVeQ+QUVERESaE7FPUe3bt0+5QBQAVq5cCQBobW3FM888AwBwOBwYHR1VYt566y2Mj49j165dGBkZwZNPPonz58/7vL3w+eefo6amBsXFxcoX/R08eDBSaRAREZEGqboGRy+CvYfH6zb0g7UkItIXNdfg6PfyaSIiIkpYbHAC8Hg8sZ4C/UcJeHKSiIj+L26+yThemM1mGI1G9Pf3Y8GCBTCbzcqNKEk7RAR//PEHDAYDTCZTrKdDRERRxgZnGqPRiPz8fAwMDKC/Pwb3n6J7xmAwIDs7G3PmzIn1VIiIKMrY4PhhNpuRm5uLf/75x+eeSaQtJpOJzQ0RUYJigxOA960Nvr1BRESkPbzImIiIiHSHDQ4RERHpDhscIiIi0p2EvAbH+/0oY2NjMZ4JERERzZb3/+3ZfM9ZQjY4LpcLAJCTkxPjmRAREZFaLpcLKSkpQWMS8l5UHo8H/f39SE5Ovudf4jc2NoacnBz8/vvvIe+ToXXMVb8SKV/mql+JlG+i5CoicLlcsFqtMBqDX2WTkGdwjEYjsrOzI/pvzJ8/X9cvsrsxV/1KpHyZq34lUr6JkGuoMzdevMiYiIiIdIcNDhEREekOG5x7zGKxwG63w2KxxHoqEcdc9SuR8mWu+pVI+SZSrrOVkBcZExERkb7xDA4RERHpDhscIiIi0h02OERERKQ7bHCIiIhId9jghOHw4cNYuHAhkpKSYLPZ0NXVFTT+yy+/xLJly5CUlISCggKcO3cuSjMN3/79+/H4448jOTkZ6enpqKyshMPhCHpMY2MjDAaDzyMpKSlKMw7fO++8M2Pey5YtC3qMFmvqtXDhwhn5GgwGVFdX+43XUl2//fZbPPfcc7BarTAYDDh9+rTPfhHBvn37kJWVhblz56KkpAS9vb0hx1W75qMhWK5TU1Oora1FQUEB5s2bB6vVipdeegn9/f1BxwxnLURLqNpu3759xtzLyspCjqu12gLwu34NBgMOHDgQcMx4rm2ksMFR6YsvvsDrr78Ou92O7u5uFBYWorS0FMPDw37jf/jhB2zZsgU7duxAT08PKisrUVlZiatXr0Z55uq0t7ejuroaFy9eRFNTE6amprBu3TqMj48HPW7+/PkYGBhQHn19fVGa8X+zfPlyn3l///33AWO1WlOvH3/80SfXpqYmAMALL7wQ8Bit1HV8fByFhYU4fPiw3/0ffvghDh48iE8++QSXLl3CvHnzUFpaisnJyYBjql3z0RIs14mJCXR3d2Pv3r3o7u7GV199BYfDgQ0bNoQcV81aiKZQtQWAsrIyn7kfP3486JharC0AnxwHBgZQX18Pg8GA559/Pui48VrbiBFSZfXq1VJdXa08d7vdYrVaZf/+/X7jN23aJOvXr/fZZrPZ5NVXX43oPO+14eFhASDt7e0BYxoaGiQlJSV6k7pH7Ha7FBYWzjpeLzX1eu2112Tx4sXi8Xj87tdqXQHIqVOnlOcej0cyMzPlwIEDyraRkRGxWCxy/PjxgOOoXfOxMD1Xf7q6ugSA9PX1BYxRuxZixV++27Ztk4qKClXj6KW2FRUVsnbt2qAxWqntvcQzOCrcuXMHly9fRklJibLNaDSipKQEnZ2dfo/p7Oz0iQeA0tLSgPHxanR0FADwwAMPBI27ffs28vLykJOTg4qKCly7di0a0/vPent7YbVasWjRImzduhW//fZbwFi91BT49zV97NgxvPzyy0FvPKvVut7N6XRicHDQp3YpKSmw2WwBaxfOmo9Xo6OjMBgMSE1NDRqnZi3Em7a2NqSnp2Pp0qXYvXs3bt26FTBWL7UdGhrC2bNnsWPHjpCxWq5tONjgqPDnn3/C7XYjIyPDZ3tGRgYGBwf9HjM4OKgqPh55PB7s2bMHTzzxBB599NGAcUuXLkV9fT3OnDmDY8eOwePxYM2aNbh582YUZ6uezWZDY2Mjzp8/j7q6OjidTjz11FNwuVx+4/VQU6/Tp09jZGQE27dvDxij1bpO562PmtqFs+bj0eTkJGpra7Fly5agN2JUuxbiSVlZGT777DO0tLTggw8+QHt7O8rLy+F2u/3G66W2n376KZKTk7Fx48agcVqubbgS8m7ipE51dTWuXr0a8v3aoqIiFBUVKc/XrFmDRx55BEeOHMF7770X6WmGrby8XPl5xYoVsNlsyMvLw8mTJ2f1V5GWHT16FOXl5bBarQFjtFpX+tfU1BQ2bdoEEUFdXV3QWC2vhaqqKuXngoICrFixAosXL0ZbWxuKi4tjOLPIqq+vx9atW0Ne+K/l2oaLZ3BUSEtLw5w5czA0NOSzfWhoCJmZmX6PyczMVBUfb2pqavD111+jtbUV2dnZqo41mUxYuXIlrl+/HqHZRUZqaiqWLFkScN5ar6lXX18fmpub8corr6g6Tqt19dZHTe3CWfPxxNvc9PX1oampKejZG39CrYV4tmjRIqSlpQWcu9ZrCwDfffcdHA6H6jUMaLu2s8UGRwWz2YxVq1ahpaVF2ebxeNDS0uLzF+7dioqKfOIBoKmpKWB8vBAR1NTU4NSpU/jmm2+Qn5+vegy3240rV64gKysrAjOMnNu3b+PGjRsB563Vmk7X0NCA9PR0rF+/XtVxWq1rfn4+MjMzfWo3NjaGS5cuBaxdOGs+Xnibm97eXjQ3N+PBBx9UPUaotRDPbt68iVu3bgWcu5Zr63X06FGsWrUKhYWFqo/Vcm1nLdZXOWvNiRMnxGKxSGNjo/zyyy+ya9cuSU1NlcHBQRERefHFF+Xtt99W4js6OuS+++6Tjz76SH799Vex2+1iMpnkypUrsUphVnbv3i0pKSnS1tYmAwMDymNiYkKJmZ7ru+++KxcuXJAbN27I5cuXpaqqSpKSkuTatWuxSGHW3njjDWlraxOn0ykdHR1SUlIiaWlpMjw8LCL6qend3G635ObmSm1t7Yx9Wq6ry+WSnp4e6enpEQDy8ccfS09Pj/LJoffff19SU1PlzJkz8vPPP0tFRYXk5+fLX3/9pYyxdu1aOXTokPI81JqPlWC53rlzRzZs2CDZ2dny008/+azhv//+Wxljeq6h1kIsBcvX5XLJm2++KZ2dneJ0OqW5uVkee+wxefjhh2VyclIZQw+19RodHZX7779f6urq/I6hpdpGChucMBw6dEhyc3PFbDbL6tWr5eLFi8q+p59+WrZt2+YTf/LkSVmyZImYzWZZvny5nD17NsozVg+A30dDQ4MSMz3XPXv2KL+XjIwMefbZZ6W7uzv6k1dp8+bNkpWVJWazWR566CHZvHmzXL9+Xdmvl5re7cKFCwJAHA7HjH1armtra6vf1603H4/HI3v37pWMjAyxWCxSXFw843eQl5cndrvdZ1uwNR8rwXJ1Op0B13Bra6syxvRcQ62FWAqW78TEhKxbt04WLFggJpNJ8vLyZOfOnTMaFT3U1uvIkSMyd+5cGRkZ8TuGlmobKQYRkYieIiIiIiKKMl6DQ0RERLrDBoeIiIh0hw0OERER6Q4bHCIiItIdNjhERESkO2xwiIiISHfY4BAREZHusMEhIiIi3WGDQ0RERLrDBoeIiIh0hw0OERER6Q4bHCIiItKd/wFq0/IRQIFosQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate data using a simple sine wave\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "def generate_data(seq_length):\n",
    "\ttime_steps = np.linspace(0, 100, seq_length + 1)\n",
    "\tdata = np.sin(time_steps)\n",
    "\tx = data[:-1]\n",
    "\ty = data[1:]\n",
    "\treturn x, y\n",
    "\n",
    "x, y = generate_data(100)\n",
    "\n",
    "# Split data into training and testing\n",
    "train_size = 80\n",
    "x_train, y_train = x[:train_size], y[:train_size]\n",
    "x_test, y_test = x[train_size:], y[train_size:]\n",
    "\n",
    "model = RNN(1, 50, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(1000):\n",
    "\tloss = 0\n",
    "\thidden = model.init_hidden()\n",
    "\toptimizer.zero_grad()\n",
    "\tfor i in range(x_train.shape[0]):\n",
    "\t\tinput = torch.tensor(x_train[i]).float().view(1, 1)\n",
    "\t\ttarget = torch.tensor(y_train[i]).float().view(1, 1)\n",
    "\t\tprediction, hidden = model(input, hidden)\n",
    "\t\tloss += criterion(prediction, target)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\tif epoch % 100 == 0:\n",
    "\t\tprint(f'Epoch {epoch} Loss: {loss.item()}')\n",
    "\n",
    "# Test the model\n",
    "hidden = model.init_hidden()\n",
    "predictions = []\n",
    "for i in range(x_test.shape[0]):\n",
    "\tinput = torch.tensor(x_test[i]).float().view(1, 1)\n",
    "\ttarget = torch.tensor(y_test[i]).float().view(1, 1)\n",
    "\tprediction, hidden = model(input, hidden)\n",
    "\tpredictions.append(prediction.item())\n",
    "\n",
    "# Print error on test set\n",
    "test_loss = criterion(torch.tensor(predictions), torch.tensor(y_test))\n",
    "print(f'Test loss: {test_loss.item()}')\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(y_test, label='True')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RNN can easily map the input sequence to the output sequence when the input and output sequences have the same length. However, in many sequence-to-sequence tasks, the input and output sequences have different lengths. In such cases, the encoder-decoder architecture with RNNs faces difficulty in capturing long-range dependencies and handling variable-length sequences.\n",
    "\n",
    "The simplest solution for general sequence-to-sequence tasks is to map the input sequence to a fixed-size context vector using one RNN and then use another RNN to generate the output sequence from the context vector. That model is called **RNN Encoder-Decoder**.\n",
    "\n",
    "The output sequence $\\mathbf{Y} = (\\mathbf{y}_1, \\mathbf{y}_2, \\ldots, \\mathbf{y}_{T'})$ may have different length from the input sequence $\\mathbf{X} = (\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_T)$. From a probabilistic perspective, this model is general method to learn the conditional probability of the output sequence given the input sequence, i.e., \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(\\mathbf{Y}|\\mathbf{X}) = \\mathbb{P}\\left(\\mathbf{y}_1, \\mathbf{y}_2, \\ldots, \\mathbf{y}_{T'}|\\mathbf{x}_1, \\mathbf{x}_2, \\ldots, \\mathbf{x}_T\\right) \\tag{3}\n",
    "\\end{equation}\n",
    "\n",
    "The encoder reads each element of the input sequence $\\mathbf{X}$ sequentially. After reading the last element, the encoder produces a fixed-size context vector $\\mathbf{c}$ that summarizes the entire input sequence. The decoder as the second RNN is then trained to generate the output sequence $\\mathbf{Y}$ by predicting the next element of the output sequence given the context vector $\\mathbf{c}$ and the hidden state of the decoder which is updated at each time step $t$ as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_t = f(\\mathbf{h}_{t-1}, \\mathbf{y}_{t-1}, \\mathbf{c}) \\tag{4}\n",
    "\\end{equation}\n",
    "\n",
    "The conditional distribution of the next element $\\mathbf{y}_t$ given the previous elements $\\mathbf{y}_{t-1},\\mathbf{y}_{t-2},\\ldots,\\mathbf{y}_1$ and the context vector $\\mathbf{c}$ is computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(\\mathbf{y}_t|\\mathbf{y}_{t-1},\\mathbf{y}_{t-2},\\ldots,\\mathbf{y}_1, \\mathbf{c}) = g(\\mathbf{h}_t, \\mathbf{y}_{t-1}, \\mathbf{c}) \\tag{5}\n",
    "\\end{equation}\n",
    "\n",
    "where $g$ is a function that maps the hidden state $\\mathbf{h}_t$, the previous output element $\\mathbf{y}_{t-1}$, and the context vector $\\mathbf{c}$ to the probability distribution over the output vocabulary.\n",
    "\n",
    "The two components of the RNN Encoder-Decoder model are trained jointly to maximize the likelihood of the output sequence given the input sequence which is equivalent to minimizing the negative log-likelihood of the output sequence given the input sequence. The loss function is defined as the sum of the negative log-likelihood of the output sequence:\n",
    "\n",
    "\\begin{equation}\n",
    "\\max_{\\theta} \\frac{1}{N} \\sum_{i=1}^{N} \\log \\mathbb{P}\\left(\\mathbf{Y}^{(i)}|\\mathbf{X}^{(i)};\\theta\\right) \\tag{6}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\theta$ denotes the parameters of the model, $\\mathbf{X}^{(i)}$ and $\\mathbf{Y}^{(i)}$ are the input and output sequences of the $i$-th training example, and $N$ is the total number of training examples.\n",
    "\n",
    "## Encoder \n",
    "\n",
    "Here we define the encoder of the RNN Encoder-Decoder model as a GRU network. The hidden state of the encoder is computed using the GRU cell at each time step.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_t = \\mathbf{z}_t \\odot \\mathbf{h}_{t-1} + (1 - \\mathbf{z}_t) \\odot \\tilde{\\mathbf{h}}_t \\tag{7}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{z}_t$ is the update gate, $\\tilde{\\mathbf{h}}_t$ is the candidate hidden state, and $\\odot$ denotes element-wise multiplication. The update gate $\\mathbf{z}_t$ and the candidate hidden state $\\tilde{\\mathbf{h}}_t$ are computed as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{z}_t & = \\sigma\\left(\\mathbf{W}^{\\text{zx}} \\mathbf{x}_t + \\mathbf{W}^{\\text{zh}} \\mathbf{h}_{t-1}\\right) = \\sigma\\left(\\mathbf{W}^{\\text{z}} \\begin{bmatrix} \\mathbf{x}_t \\\\ \\mathbf{h}_{t-1}\\end{bmatrix}\\right) \\tag{8.1} \\\\\n",
    "\\mathbf{r}_t & = \\sigma\\left(\\mathbf{W}^{\\text{rx}} \\mathbf{x}_t + \\mathbf{W}^{\\text{rh}} \\mathbf{h}_{t-1}\\right) = \\sigma\\left(\\mathbf{W}^{\\text{r}} \\begin{bmatrix} \\mathbf{x}_t \\\\ \\mathbf{h}_{t-1}\\end{bmatrix}\\right) \\tag{8.2} \\\\\n",
    "\\tilde{\\mathbf{h}}_t & = \\phi\\left(\\mathbf{W}^{\\text{hx}} \\mathbf{x}_t + \\mathbf{W}^{\\text{hh}} (\\mathbf{r}_t \\odot \\mathbf{h}_{t-1})\\right) = \\phi\\left(\\mathbf{W}^{\\text{h}} \\begin{bmatrix} \\mathbf{x}_t \\\\ \\mathbf{r}_t \\odot \\mathbf{h}_{t-1}\\end{bmatrix}\\right) \\tag{8.3}\n",
    "\\end{align*}\n",
    "\n",
    "where $\\sigma$ is the sigmoid activation function, $\\phi$ is the hyperbolic tangent activation function, and $\\mathbf{W}^{\\text{z}}$, $\\mathbf{W}^{\\text{r}}$, and $\\mathbf{W}^{\\text{h}}$ are the weight matrices for the update gate, reset gate, and candidate hidden state, respectively. Denote $d$ as the dimension of the input $\\mathbf{x}_t$ and $p$ as the dimension of the hidden state $\\mathbf{h}_t$, the meaning of the symbols are as follows:\n",
    "\n",
    "* $\\mathbf{x}_t \\in \\mathbb{R}^{d\\times 1}$ is the input at time step $t$.\n",
    "* $\\mathbf{h}_{t-1} \\in \\mathbb{R}^{p\\times 1}$ is the previous hidden state.\n",
    "* $\\tilde{\\mathbf{h}}_t \\in \\mathbb{R}^{p\\times 1}$ is the candidate hidden state.\n",
    "* $\\mathbf{z}_t \\in (0, 1)^{p\\times 1}$ is the update gate.\n",
    "* $\\mathbf{r}_t \\in (0, 1)^{p\\times 1}$ is the reset gate.\n",
    "* $\\mathbf{W}^{\\text{zx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{zh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{rx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{rh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{hx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{hh}} \\in \\mathbb{R}^{p\\times p}$ are the weight matrices.\n",
    "\n",
    "The input sequence $\\mathbf{x}$ has a length $T$, once the hidden state $\\mathbf{h}_T$ is computed, it is used as the context vector to generate the output sequence.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{c} = \\tanh \\left(\\mathbf{W}^{\\text{ch}} \\mathbf{h}_T\\right) \\tag{9}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}^{\\text{ch}} \\in \\mathbb{R}^{p\\times p}$ is the weight matrix and $\\mathbf{c} \\in \\mathbb{R}^{p\\times 1}$ is the context vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a RNN encoder-decoder\n",
    "\n",
    "# Encoder based on GRU\n",
    "class SimpleGRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, dropout=0.5):\n",
    "        super(SimpleGRUEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.W_z = nn.Linear(emb_dim + hidden_dim, hidden_dim)\n",
    "        self.W_r = nn.Linear(emb_dim + hidden_dim, hidden_dim)\n",
    "        self.W_h = nn.Linear(emb_dim + hidden_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        # src: [src_len, batch_size]\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # embedded: [src_len, batch_size, emb_dim]\n",
    "\n",
    "        h = torch.zeros(src.size(1), self.hidden_dim).to(src.device)\n",
    "        # Initialize hidden state h: [batch_size, hidden_dim]\n",
    "\n",
    "        for t in range(src.size(0)):\n",
    "            h = self.gru_cell(embedded[t], h)\n",
    "        \n",
    "        return h\n",
    "\n",
    "    def gru_cell(self, x_t, h_prev):\n",
    "        # x_t: [batch_size, emb_dim]\n",
    "        # h_prev: [batch_size, hidden_dim]\n",
    "        \n",
    "        combined = torch.cat((x_t, h_prev), dim=1)\n",
    "        # combined: [batch_size, emb_dim + hidden_dim]\n",
    "        \n",
    "        z_t = torch.sigmoid(self.W_z(combined))\n",
    "        r_t = torch.sigmoid(self.W_r(combined))\n",
    "        \n",
    "        combined_reset = torch.cat((x_t, r_t * h_prev), dim=1)\n",
    "        h_tilde_t = torch.tanh(self.W_h(combined_reset))\n",
    "        \n",
    "        h_t = z_t * h_prev + (1 - z_t) * h_tilde_t\n",
    "        \n",
    "        return h_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "The decoder is also a GRU network that generates the output sequence based on the context vector provided by the encoder. It starts with the initial hidden state $\\mathbf{h}_0$ which is computed as a function of the context vector $\\mathbf{c}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_0 = \\tanh\\left(\\mathbf{W}^{\\text{hc}} \\mathbf{c}\\right) \\tag{10}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}^{\\text{hc}} \\in \\mathbb{R}^{p\\times p}$ is the weight matrix.\n",
    "\n",
    "The hidden state $\\mathbf{h}_t$ at time step $t$ is computed using the GRU cell as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_t = \\mathbf{z}_t \\odot \\mathbf{h}_{t-1} + (1 - \\mathbf{z}_t) \\odot \\tilde{\\mathbf{h}}_t \\tag{11}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{z}_t$ is the update gate, $\\tilde{\\mathbf{h}}_t$ is the candidate hidden state, and they are computed as follows:\n",
    "\n",
    "\\begin{align*}\n",
    "\\mathbf{z}_t & = \\sigma\\left(\\mathbf{W}^{\\text{zx}} \\mathbf{y}_{t-1} + \\mathbf{W}^{\\text{zh}} \\mathbf{h}_{t-1} + \\mathbf{W}^{\\text{zc}} \\mathbf{c}\\right) = \\sigma\\left(\\mathbf{W}^{\\text{z}} \\begin{bmatrix} \\mathbf{y}_{t-1} \\\\ \\mathbf{h}_{t-1} \\\\ \\mathbf{c}\\end{bmatrix}\\right) \\tag{12.1} \\\\\n",
    "\\mathbf{r}_t & = \\sigma\\left(\\mathbf{W}^{\\text{rx}} \\mathbf{y}_{t-1} + \\mathbf{W}^{\\text{rh}} \\mathbf{h}_{t-1} + \\mathbf{W}^{\\text{rc}} \\mathbf{c}\\right) = \\sigma\\left(\\mathbf{W}^{\\text{r}} \\begin{bmatrix} \\mathbf{y}_{t-1} \\\\ \\mathbf{h}_{t-1} \\\\ \\mathbf{c}\\end{bmatrix}\\right) \\tag{12.2} \\\\\n",
    "\\tilde{\\mathbf{h}}_t & = \\phi\\left(\\mathbf{W}^{\\text{hx}} \\mathbf{y}_{t-1} + \\mathbf{r}_t \\odot \\left( \\mathbf{W}^{\\text{hh}} \\mathbf{h}_{t-1} + \\mathbf{W}^{\\text{hc}} \\mathbf{c} \\right)\\right) \\tag{12.3}\n",
    "\\end{align*}\n",
    "\n",
    "The symbols have the similar meaning as in the encoder:\n",
    "\n",
    "* $\\mathbf{y}_{t-1} \\in \\mathbb{R}^{d\\times 1}$ is the previous output at time step $t-1$.\n",
    "* $\\mathbf{h}_{t-1} \\in \\mathbb{R}^{p\\times 1}$ is the previous hidden state.\n",
    "* $\\tilde{\\mathbf{h}}_t \\in \\mathbb{R}^{p\\times 1}$ is the candidate hidden state.\n",
    "* $\\mathbf{z}_t \\in (0, 1)^{p\\times 1}$ is the update gate.\n",
    "* $\\mathbf{r}_t \\in (0, 1)^{p\\times 1}$ is the reset gate.\n",
    "* $\\mathbf{W}^{\\text{zx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{zh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{zc}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{rx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{rh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{rc}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{hx}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{hh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{hc}} \\in \\mathbb{R}^{p\\times p}$ are the weight matrices.\n",
    "\n",
    "Unlike the encoder, the decoder generates the output sequence one element at a time. The probability distribution over the output vocabulary at time step $t$ is computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbb{P}(\\mathbf{y}_t|\\mathbf{y}_{t-1},\\mathbf{y}_{t-2},\\ldots,\\mathbf{y}_1, \\mathbf{X}) = \\text{softmax}\\left(\\mathbf{G}\\mathbf{s}_t\\right) \\tag{13}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{s}_t$ is the maxout unit, and $\\mathbf{G} \\in \\mathbb{R}^{d\\times p}$ is the weight matrix.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{s}_t = \\text{maxout}\\left(\\mathbf{W}^{\\text{sy}} \\mathbf{y}_{t-1} + \\mathbf{W}^{\\text{sh}} \\mathbf{h}_t + \\mathbf{W}^{\\text{sc}} \\mathbf{c}\\right) \\tag{14}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}^{\\text{sy}} \\in \\mathbb{R}^{p\\times d}$, $\\mathbf{W}^{\\text{sh}} \\in \\mathbb{R}^{p\\times p}$, $\\mathbf{W}^{\\text{sc}} \\in \\mathbb{R}^{p\\times p}$ are the weight matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class SimpleGRUDecoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, dropout=0.5):\n",
    "        super(SimpleGRUDecoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.W_z = nn.Linear(emb_dim + hidden_dim + hidden_dim, hidden_dim)\n",
    "        self.W_r = nn.Linear(emb_dim + hidden_dim + hidden_dim, hidden_dim)\n",
    "        self.W_hx = nn.Linear(emb_dim, hidden_dim)\n",
    "        self.W_hh = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.W_hc = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden, context):\n",
    "        # input: [batch_size]\n",
    "        # hidden: [batch_size, hidden_dim]\n",
    "        # context: [batch_size, hidden_dim]\n",
    "\n",
    "        # Embed input word\n",
    "        embedded = self.dropout(self.embedding(input.unsqueeze(0)))  # [1, batch_size, emb_dim]\n",
    "\n",
    "        # Prepare GRU cell input\n",
    "        combined = torch.cat((embedded, hidden.unsqueeze(0), context.unsqueeze(0)), dim=2)  # [1, batch_size, emb_dim + hidden_dim + hidden_dim]\n",
    "\n",
    "        # Compute GRU gates\n",
    "        z_t = torch.sigmoid(self.W_z(combined)).squeeze(0)  # [batch_size, hidden_dim]\n",
    "        r_t = torch.sigmoid(self.W_r(combined)).squeeze(0)  # [batch_size, hidden_dim]\n",
    "        \n",
    "        # Compute candidate hidden state\n",
    "        h_h = self.W_hh(hidden)\n",
    "        h_c = self.W_hc(context)\n",
    "        combined_reset = self.W_hx(embedded.squeeze(0)) + r_t * (h_h + h_c)  # [batch_size, hidden_dim]\n",
    "        h_tilde_t = torch.tanh(combined_reset)  # [batch_size, hidden_dim]\n",
    "\n",
    "        # Compute new hidden state\n",
    "        h_t = z_t * hidden + (1 - z_t) * h_tilde_t  # [batch_size, hidden_dim]\n",
    "\n",
    "        # Generate output prediction\n",
    "        output = self.fc_out(h_t)  # [batch_size, output_dim]\n",
    "        \n",
    "        return output, h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSeq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(SimpleSeq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        # Encode the source sequence\n",
    "        context = self.encoder(src)\n",
    "        \n",
    "        # Initialize hidden state h0 as a function of context vector c\n",
    "        hidden = torch.tanh(self.decoder.W_hc(context))\n",
    "        \n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden, context)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence-to-Sequence Model with Attention Mechanism\n",
    "\n",
    "The attention mechanism addresses the limitation of the fixed-length context vector by allowing the decoder to focus on different parts of the input sequence at each step of the output generation. This improves the model's performance, especially for long sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder class\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hidden_dim, n_layers, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM(emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        return outputs, hidden, cell\n",
    "\n",
    "# Attention class\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.v = nn.Parameter(torch.rand(hidden_dim))\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        concat = torch.cat((hidden, encoder_outputs), dim=2)\n",
    "        energy = torch.tanh(self.attn(concat))\n",
    "        energy = energy.permute(0, 2, 1)\n",
    "        v = self.v.repeat(encoder_outputs.shape[0], 1).unsqueeze(1)\n",
    "        attention = torch.bmm(v, energy).squeeze(1)\n",
    "        return torch.softmax(attention, dim=1)\n",
    "\n",
    "# Decoder class\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hidden_dim, n_layers, dropout, attention):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.LSTM((hidden_dim * 2) + emb_dim, hidden_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear((hidden_dim * 2) + emb_dim + hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, cell, encoder_outputs):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        a = self.attention(hidden[-1], encoder_outputs)\n",
    "        a = a.unsqueeze(1)\n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
    "        output, (hidden, cell) = self.rnn(rnn_input, (hidden, cell))\n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim=1))\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "# Seq2Seq class\n",
    "class Seq2SeqAttention(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2SeqAttention, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        batch_size = trg.shape[1]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        encoder_outputs, hidden, cell = self.encoder(src)\n",
    "        \n",
    "        input = trg[0, :]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input = trg[t] if random.random() < teacher_forcing_ratio else top1\n",
    "            \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SortingDataset(Dataset):\n",
    "    def __init__(self, num_samples, seq_len):\n",
    "        self.num_samples = num_samples\n",
    "        self.seq_len = seq_len\n",
    "        self.data = [np.random.permutation(seq_len) for _ in range(num_samples)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.data[idx]\n",
    "        sorted_seq = np.argsort(seq)\n",
    "        return torch.tensor(seq, dtype=torch.long), torch.tensor(sorted_seq, dtype=torch.long)\n",
    "\n",
    "def get_data_loaders(num_samples, seq_len, batch_size, split_ratio=0.8):\n",
    "    dataset = SortingDataset(num_samples, seq_len)\n",
    "    train_size = int(split_ratio * len(dataset))\n",
    "    test_size = len(dataset) - train_size\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader\n",
    "\n",
    "train_loader, test_loader = get_data_loaders(1000, 10, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(tensor, use_cuda=torch.cuda.is_available()):\n",
    "    if use_cuda:\n",
    "        return tensor.cuda()\n",
    "    return tensor\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb = nn.Embedding(input_size, emb_size)\n",
    "        self.lstm = nn.LSTM(emb_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.emb(input)\n",
    "        # print(f\"Embedded shape: {embedded.shape}\")  # Debugging line\n",
    "        encoder_states, (h_n, c_n) = self.lstm(embedded)\n",
    "        # print(f\"Encoder states shape: {encoder_states.shape}\")  # Debugging line\n",
    "        return encoder_states, (h_n, c_n)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, weight_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.weight_size = weight_size\n",
    "\n",
    "        self.dec = nn.LSTMCell(emb_size, hidden_size)\n",
    "        self.W1 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.W2 = nn.Linear(hidden_size, weight_size, bias=False)\n",
    "        self.vt = nn.Linear(weight_size, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_states, h_n, c_n, answer_seq_len):\n",
    "        batch_size = encoder_states.size(1)\n",
    "        decoder_input = torch.zeros(batch_size, self.emb_size).to(encoder_states.device)\n",
    "        hidden = h_n[-1]  # Use the last layer's hidden state from the encoder\n",
    "        cell_state = c_n[-1]  # Use the last layer's cell state from the encoder\n",
    "\n",
    "        probs = []\n",
    "        for i in range(answer_seq_len):\n",
    "            hidden, cell_state = self.dec(decoder_input, (hidden, cell_state))\n",
    "\n",
    "            blend1 = self.W1(encoder_states)  # (L, bs, W)\n",
    "            blend2 = self.W2(hidden).unsqueeze(0)  # (1, bs, W)\n",
    "            blend_sum = torch.tanh(blend1 + blend2)  # (L, bs, W)\n",
    "            out = self.vt(blend_sum).squeeze()  # (L, bs)\n",
    "            if out.dim() == 1:\n",
    "                out = out.unsqueeze(1)  # Ensure out is 2D (L, bs)\n",
    "            out = F.log_softmax(out, dim=0).transpose(0, 1).contiguous()  # (bs, L)\n",
    "            probs.append(out)\n",
    "\n",
    "            decoder_input = torch.zeros(batch_size, self.emb_size).to(encoder_states.device)\n",
    "\n",
    "        probs = torch.stack(probs, dim=1)\n",
    "        return probs\n",
    "\n",
    "\n",
    "class PointerNetwork(nn.Module):\n",
    "    def __init__(self, input_size, emb_size, weight_size, answer_seq_len, hidden_size=512):\n",
    "        super(PointerNetwork, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(input_size, emb_size, hidden_size)\n",
    "        self.decoder = Decoder(emb_size, hidden_size, weight_size)\n",
    "        self.answer_seq_len = answer_seq_len\n",
    "\n",
    "    def forward(self, input):\n",
    "        encoder_states, (h_n, c_n) = self.encoder(input)\n",
    "        encoder_states = encoder_states.transpose(1, 0)\n",
    "        probs = self.decoder(encoder_states, h_n, c_n, self.answer_seq_len)\n",
    "        return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 2.0826363563537598\n",
      "Epoch 2/20, Loss: 1.004944920539856\n",
      "Epoch 3/20, Loss: 0.2557021677494049\n",
      "Epoch 4/20, Loss: 0.05096918344497681\n",
      "Epoch 5/20, Loss: 0.02094600349664688\n",
      "Epoch 6/20, Loss: 0.012992252595722675\n",
      "Epoch 7/20, Loss: 0.00915723480284214\n",
      "Epoch 8/20, Loss: 0.00698508694767952\n",
      "Epoch 9/20, Loss: 0.005433091428130865\n",
      "Epoch 10/20, Loss: 0.00462177162989974\n",
      "Epoch 11/20, Loss: 0.0036990877706557512\n",
      "Epoch 12/20, Loss: 0.003148105461150408\n",
      "Epoch 13/20, Loss: 0.0027289208956062794\n",
      "Epoch 14/20, Loss: 0.002390689915046096\n",
      "Epoch 15/20, Loss: 0.0021308916620910168\n",
      "Epoch 16/20, Loss: 0.001824558014050126\n",
      "Epoch 17/20, Loss: 0.0016584962140768766\n",
      "Epoch 18/20, Loss: 0.0015310647431761026\n",
      "Epoch 19/20, Loss: 0.001405179500579834\n",
      "Epoch 20/20, Loss: 0.001298849587328732\n"
     ]
    }
   ],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for seq, target in train_loader:\n",
    "            seq, target = seq.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(seq)\n",
    "            outputs = outputs.view(-1, outputs.size(-1)) # (bs*M, L)\n",
    "            target = target.view(-1) # (bs*M)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "input_size = 20\n",
    "emb_size = 128\n",
    "weight_size = 128\n",
    "answer_seq_len = 10\n",
    "hidden_size = 128\n",
    "\n",
    "model = PointerNetwork(input_size, emb_size, weight_size, answer_seq_len, hidden_size)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "train(model, train_loader, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for seq, target in test_loader:\n",
    "            seq, target = seq.to(device), target.to(device)\n",
    "                \n",
    "            outputs = model(seq)\n",
    "            predicted = torch.argmax(outputs, dim=-1)\n",
    "            total += target.size(0) * target.size(1)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    print(f'Accuracy: {100 * correct / total:.2f}%')\n",
    "\n",
    "evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 13\u001b[0m     output_probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (1, answer_seq_len, seq_len)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Get the sorted indices from the output probabilities\u001b[39;00m\n\u001b[0;32m     16\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output_probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# shape: (1, answer_seq_len)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 67\u001b[0m, in \u001b[0;36mPointerNetwork.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     65\u001b[0m encoder_states, (h_n, c_n) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m     66\u001b[0m encoder_states \u001b[38;5;241m=\u001b[39m encoder_states\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_n\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manswer_seq_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m probs\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 33\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, encoder_states, h_n, c_n, answer_seq_len)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoder_states, h_n, c_n, answer_seq_len):\n\u001b[0;32m     32\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m encoder_states\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m     decoder_input \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m h_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Use the last layer's hidden state from the encoder\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     cell_state \u001b[38;5;241m=\u001b[39m c_n[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Use the last layer's cell state from the encoder\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Suppose your input sequence is like this (replace this with your actual sequence)\n",
    "sequence = torch.tensor([3, 10, 2, 0, 20, 6, 5, 7, 15, 8], dtype=torch.long)  # Example sequence of length 10\n",
    "\n",
    "# Make sure the sequence is a 2D tensor (batch_size, seq_len)\n",
    "sequence = sequence.unsqueeze(0)  # shape: (1, seq_len)\n",
    "\n",
    "# Move the sequence to the appropriate device\n",
    "sequence = sequence.to(device)\n",
    "\n",
    "# Pass the sequence through the model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output_probs = model(sequence)  # shape: (1, answer_seq_len, seq_len)\n",
    "\n",
    "# Get the sorted indices from the output probabilities\n",
    "sorted_indices = torch.argmax(output_probs, dim=-1)  # shape: (1, answer_seq_len)\n",
    "sorted_indices = sorted_indices.squeeze(0)  # shape: (answer_seq_len)\n",
    "\n",
    "# Sort the original sequence using the sorted indices\n",
    "sorted_sequence = sequence.squeeze(0)[sorted_indices]\n",
    "\n",
    "# Print the sorted sequence\n",
    "print(\"Original sequence:\", sequence.squeeze(0).cpu().numpy())\n",
    "print(\"Sorted indices:\", sorted_indices.cpu().numpy())\n",
    "print(\"Sorted sequence:\", sorted_sequence.cpu().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
